{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deeed32a",
   "metadata": {},
   "source": [
    "# Multimodal Network\n",
    "\n",
    "Create GNN for each of the dimensions and later combine them into a single network.\n",
    "\n",
    "1. Each dimension is a separate graph and gets its own GNN.\n",
    "2. Dimensions are connected in a MLP layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa47f5",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ce967bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Current working directory: /home/jovyan/dlss-project\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "import country_converter as coco\n",
    "import functools\n",
    "\n",
    "# Set up device (is available use GPU to speed up computations)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "os.chdir('/home/jovyan/dlss-project')\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4987e0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d38f27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_geo_edges = \"data_collection/geography/edges_yearly_dist_enc.parquet\"\n",
    "path_geo_nodes = \"data_collection/geography/nodes_enc.parquet\"\n",
    "df_geo_edges = pd.read_parquet(path_geo_edges)\n",
    "df_geo_nodes = pd.read_parquet(path_geo_nodes)\n",
    "\n",
    "path_pol_edges = \"data_collection/political/data/edge_features.parquet\"\n",
    "path_pol_nodes = \"data_collection/political/data/node_features.parquet\"\n",
    "df_pol_edges = pd.read_parquet(path_pol_edges)\n",
    "df_pol_nodes = pd.read_parquet(path_pol_nodes)\n",
    "\n",
    "path_cult_edges = \"data_collection/culture/culture_edges.parquet\"\n",
    "path_cult_nodes = \"data_collection/culture/culture_nodes.parquet\"\n",
    "df_cult_edges = pd.read_parquet(path_cult_edges)\n",
    "df_cult_nodes = pd.read_parquet(path_cult_nodes)\n",
    "\n",
    "path_lang_edges = \"data_collection/culture/language_religion_edges.parquet\"\n",
    "path_lang_nodes = \"data_collection/culture/language_religion_nodes.parquet\"\n",
    "df_lang_edges = pd.read_parquet(path_lang_edges)\n",
    "df_lang_nodes = pd.read_parquet(path_lang_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9dfe5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute UN member countries once\n",
    "@functools.lru_cache(maxsize=1)\n",
    "def get_un_countries():\n",
    "    \"\"\"Cache UN member countries to avoid repeated lookups\"\"\"\n",
    "    iso3 = coco.CountryConverter().data[coco.CountryConverter().data['UNmember'].notna()]['ISO3'].dropna().tolist()\n",
    "    unnumeric = coco.CountryConverter().data[coco.CountryConverter().data['UNmember'].notna()]['UNcode'].dropna().tolist()\n",
    "    return iso3, unnumeric\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=1000)\n",
    "def convert_country_code(country, target_format='UNnumeric'):\n",
    "    \"\"\"Cache country code conversions\"\"\"\n",
    "    return coco.convert(names=country, to=target_format, not_found=None)\n",
    "\n",
    "def create_data(edge_df, node_df, edge_country_a_col, edge_country_b_col, node_country_col, year_col=\"year\"):\n",
    "    # Get UN countries once\n",
    "    uno_iso3_codes, uno_unnumeric_codes = get_un_countries()\n",
    "\n",
    "    # Pre-filter dataframes\n",
    "    edge_mask = edge_df[edge_country_a_col].isin(uno_iso3_codes) & edge_df[edge_country_b_col].isin(uno_iso3_codes)\n",
    "    node_mask = node_df[node_country_col].isin(uno_iso3_codes)\n",
    "\n",
    "    edge_df = edge_df[edge_mask].copy()\n",
    "    node_df = node_df[node_mask].copy()\n",
    "\n",
    "    # Ensure year is int before unique extraction\n",
    "    edge_df[year_col] = edge_df[year_col].astype(int)\n",
    "    node_df[year_col] = node_df[year_col].astype(int)\n",
    "\n",
    "    print(f\"Number of edges after filtering: {len(edge_df)}\")\n",
    "    print(f\"Number of nodes after filtering: {len(node_df)}\")\n",
    "\n",
    "    # Vectorized country code conversion\n",
    "    unique_countries_edges = pd.concat([edge_df[edge_country_a_col], edge_df[edge_country_b_col]]).unique()\n",
    "    unique_countries_nodes = node_df[node_country_col].unique()\n",
    "    all_unique_countries = np.unique(np.concatenate([unique_countries_edges, unique_countries_nodes]))\n",
    "\n",
    "    country_to_id_map = dict(zip(\n",
    "        all_unique_countries,\n",
    "        coco.convert(all_unique_countries.tolist(), to='UNnumeric', not_found=None)\n",
    "    ))\n",
    "\n",
    "    # Apply mapping\n",
    "    edge_df['country_id_a'] = edge_df[edge_country_a_col].map(country_to_id_map)\n",
    "    edge_df['country_id_b'] = edge_df[edge_country_b_col].map(country_to_id_map)\n",
    "    node_df['country_id'] = node_df[node_country_col].map(country_to_id_map)\n",
    "\n",
    "    # Drop any rows where mapping failed (shouldn't if filters were correct)\n",
    "    edge_df = edge_df.dropna(subset=['country_id_a', 'country_id_b'])\n",
    "    node_df = node_df.dropna(subset=['country_id'])\n",
    "\n",
    "    # Cast country_id to int\n",
    "    edge_df['country_id_a'] = edge_df['country_id_a'].astype(int)\n",
    "    edge_df['country_id_b'] = edge_df['country_id_b'].astype(int)\n",
    "    node_df['country_id'] = node_df['country_id'].astype(int)\n",
    "\n",
    "    data_dict = {}\n",
    "    years = edge_df[year_col].unique()\n",
    "    \n",
    "    # limit years from 2000 to 2022\n",
    "    years = [year for year in years if 2000 <= year <= 2022]\n",
    "\n",
    "    for year in years:\n",
    "        edge_df_year = edge_df[edge_df[year_col] == year]\n",
    "        node_df_year = node_df[node_df[year_col] == year].copy()  # copy because we'll potentially modify\n",
    "                \n",
    "        # --- Edge features ---\n",
    "        edge_features_cols = [\n",
    "            col for col in edge_df_year.columns\n",
    "            if col not in ['country_id_a', 'country_id_b', edge_country_a_col, edge_country_b_col, year_col]\n",
    "        ]\n",
    "        edge_features_df = edge_df_year[edge_features_cols].copy()\n",
    "\n",
    "        # Boolean to int\n",
    "        bool_cols_edges = edge_features_df.select_dtypes(include='bool').columns\n",
    "        if len(bool_cols_edges) > 0:\n",
    "            edge_features_df[bool_cols_edges] = edge_features_df[bool_cols_edges].astype(int)\n",
    "\n",
    "        # Coerce all edge feature columns to numeric, fill NaN with 0\n",
    "        edge_features_df = edge_features_df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "        # --- Node features ---\n",
    "        node_features_cols = [\n",
    "            col for col in node_df_year.columns\n",
    "            if col not in ['country_id', node_country_col, year_col]\n",
    "        ]\n",
    "\n",
    "        # Add missing countries (so each year has all UN countries)\n",
    "        existing_countries = set(node_df_year['country_id'])\n",
    "        missing_countries = set(uno_unnumeric_codes) - existing_countries\n",
    "        \n",
    "        # Boolean to int for node features\n",
    "        bool_cols_nodes = node_df_year.select_dtypes(include='bool').columns\n",
    "        if len(bool_cols_nodes) > 0:\n",
    "            node_df_year[bool_cols_nodes] = node_df_year[bool_cols_nodes].astype(int)\n",
    "            \n",
    "        # add column to state if country does exist in this year/dataset\n",
    "        node_df_year['exists'] = 1\n",
    "\n",
    "        if missing_countries:\n",
    "            # Build missing rows once\n",
    "            for country in missing_countries:\n",
    "                missing_row = {col: 0 for col in node_features_cols}\n",
    "                missing_row['country_id'] = country\n",
    "                missing_row['year'] = year\n",
    "                missing_row['exists'] = 0\n",
    "                row_df = pd.DataFrame([missing_row])\n",
    "                node_df_year = pd.concat([node_df_year, row_df], ignore_index=True)\n",
    "\n",
    "        # Ensure node_df_year is sorted by country_id and align features accordingly\n",
    "        node_df_year_sorted = node_df_year.sort_values(by='country_id').reset_index(drop=True)\n",
    "        \n",
    "        # select only feature columns\n",
    "        node_df_year_features = node_df_year_sorted[node_features_cols].copy()\n",
    "        \n",
    "        country_id_tensor = torch.tensor(node_df_year_sorted['country_id'].values, dtype=torch.long)\n",
    "\n",
    "        # --- Tensor creation ---\n",
    "        edge_features_array = edge_features_df.values.astype(np.float32)\n",
    "        edge_attr = torch.from_numpy(edge_features_array)\n",
    "\n",
    "        node_features_tensor = torch.tensor(node_df_year_features.values, dtype=torch.float32)\n",
    "        edge_index = torch.tensor(\n",
    "            edge_df_year[['country_id_a', 'country_id_b']].values.T,\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        data = Data(x=node_features_tensor, edge_index=edge_index, edge_attr=edge_attr, country_id = country_id_tensor)\n",
    "        data_dict[year] = data\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "211b72f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges after filtering: 782920\n",
      "Number of nodes after filtering: 4402\n",
      "Number of edges after filtering: 54716\n",
      "Number of nodes after filtering: 2548\n",
      "Number of edges after filtering: 852288\n",
      "Number of nodes after filtering: 4186\n"
     ]
    }
   ],
   "source": [
    "geo_data = create_data(df_geo_edges, df_geo_nodes, \n",
    "                        edge_country_a_col='iso_o', edge_country_b_col='iso_d',\n",
    "                        node_country_col='code_3', year_col='year')\n",
    "\n",
    "# pol_data = create_data(df_pol_edges, df_pol_nodes,\n",
    "#                         edge_country_a_col='country_id_a', edge_country_b_col='country_id_b',\n",
    "#                         node_country_col='country_id', year_col='year')\n",
    "\n",
    "cul_data = create_data(df_cult_edges, df_cult_nodes,\n",
    "                        edge_country_a_col='ISO3_a', edge_country_b_col='ISO3_b',\n",
    "                        node_country_col='ISO3', year_col='year')\n",
    "\n",
    "lang_data = create_data(df_lang_edges, df_lang_nodes,\n",
    "                        edge_country_a_col='country_a', edge_country_b_col='country_b',\n",
    "                        node_country_col='ISO3', year_col='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb82dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO extract GINI and add to complete data\n",
    "\n",
    "data_years = {}\n",
    "\n",
    "for year in geo_data.keys():\n",
    "    network_data = {\n",
    "        'geography': geo_data[year],\n",
    "        'political': pol_data[year] if 'pol_data' in locals() else None,\n",
    "        'culture': cul_data[year],\n",
    "        'language': lang_data[year] if 'lang_data' in locals() else None,\n",
    "        'economy': None,  # Placeholder for future economy data\n",
    "        'GINI': None  # Placeholder for GINI data\n",
    "    }\n",
    "    data_years[year] = network_data\n",
    "    \n",
    "# get the dimesions of each network: number of node_features, number of edge-features\n",
    "network_dimesions = {\n",
    "    'geography': {\n",
    "        'node_features': geo_data[2000].x.shape[1],\n",
    "        'edge_features': geo_data[2000].edge_attr.shape[1]\n",
    "    },\n",
    "    'political': {\n",
    "        'node_features': pol_data[2000].x.shape[1],\n",
    "        'edge_features': pol_data[2000].edge_attr.shape[1]\n",
    "    } if 'pol_data' in locals() else None,\n",
    "    'culture': {\n",
    "        'node_features': cul_data[2000].x.shape[1],\n",
    "        'edge_features': cul_data[2000].edge_attr.shape[1]\n",
    "    },\n",
    "    'language': {\n",
    "        'node_features': lang_data[2000].x.shape[1],\n",
    "        'edge_features': lang_data[2000].edge_attr.shape[1]\n",
    "    } if 'lang_data' in locals() else None,\n",
    "    'economy': None,  # Placeholder for future economy data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd1a42",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe56378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN model for each of the different networks\n",
    "\n",
    "class DimensionModel(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, hidden_size=32, target_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.target_size = target_size\n",
    "        self.convs = [GATv2Conv(self.num_node_features, self.hidden_size, edge_dim = num_edge_features),\n",
    "                      GATv2Conv(self.hidden_size, self.hidden_size, edge_dim = num_edge_features)]\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr) # adding edge features here!\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MultiModalGNNModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dims,  # list of (num_node_features, num_edge_features) per modality\n",
    "                 hidden_size=32, \n",
    "                 fusion_hidden_size=64, \n",
    "                 final_output_size=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.geo_model = DimensionModel(input_dims['geography']['n_node_features'], \n",
    "                                        input_dims['geography']['n_edge_features'], hidden_size)\n",
    "        self.pol_model = DimensionModel(input_dims['political']['n_node_features'], \n",
    "                                        input_dims['political']['n_edge_features'], hidden_size)\n",
    "        self.cult_model = DimensionModel(input_dims['culture']['n_node_features'], \n",
    "                                        input_dims['culture']['n_edge_features'], hidden_size)\n",
    "        self.lang_model = DimensionModel(input_dims['language']['n_node_features'], \n",
    "                                        input_dims['language']['n_edge_features'], hidden_size)\n",
    "\n",
    "        self.fusion_input_size = hidden_size * len(input_dims)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.fusion_input_size, fusion_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fusion_hidden_size, final_output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, data_dict):\n",
    "        geo_emb = self.geo_model(data_dict['geography'])\n",
    "        pol_emb = self.pol_model(data_dict['political'])\n",
    "        cult_emb = self.cult_model(data_dict['culture'])\n",
    "        lang_emb = self.lang_model(data_dict['language'])\n",
    "        \n",
    "        embeddings = [geo_emb, pol_emb, cult_emb, lang_emb]\n",
    "\n",
    "        fused = torch.cat(embeddings, dim=-1)  # shape: [num_nodes, hidden_size * num_modalities]\n",
    "        output = self.mlp(fused)               # shape: [num_nodes, final_output_size]\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlss)",
   "language": "python",
   "name": "dlss_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
