{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deeed32a",
   "metadata": {},
   "source": [
    "# Multimodal Network\n",
    "\n",
    "Create GNN for each of the dimensions and later combine them into a single network.\n",
    "\n",
    "1. Each dimension is a separate graph and gets its own GNN.\n",
    "2. Dimensions are connected in a MLP layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce967bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Current working directory: /home/jovyan/dlss-project\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "import country_converter as coco\n",
    "import functools\n",
    "\n",
    "# Set up device (is available use GPU to speed up computations)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "os.chdir('/home/jovyan/dlss-project')\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4987e0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d38f27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_geo_edges = \"data_collection/geography/edges_yearly_dist_enc.parquet\"\n",
    "path_geo_nodes = \"data_collection/geography/nodes_enc.parquet\"\n",
    "df_geo_edges = pd.read_parquet(path_geo_edges)\n",
    "df_geo_nodes = pd.read_parquet(path_geo_nodes)\n",
    "\n",
    "path_pol_edges = \"data_collection/political/data/edge_features.parquet\"\n",
    "path_pol_nodes = \"data_collection/political/data/node_features.parquet\"\n",
    "df_pol_edges = pd.read_parquet(path_pol_edges)\n",
    "df_pol_nodes = pd.read_parquet(path_pol_nodes)\n",
    "\n",
    "path_cult_edges = \"data_collection/culture/culture_edges.parquet\"\n",
    "path_cult_nodes = \"data_collection/culture/culture_nodes.parquet\"\n",
    "df_cult_edges = pd.read_parquet(path_cult_edges)\n",
    "df_cult_nodes = pd.read_parquet(path_cult_nodes)\n",
    "\n",
    "path_lang_edges = \"data_collection/culture/language_religion_edges.parquet\"\n",
    "path_lang_nodes = \"data_collection/culture/language_religion_nodes.parquet\"\n",
    "df_lang_edges = pd.read_parquet(path_lang_edges)\n",
    "df_lang_nodes = pd.read_parquet(path_lang_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dfe5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute UN member countries once\n",
    "@functools.lru_cache(maxsize=1)\n",
    "def get_un_countries():\n",
    "    \"\"\"Cache UN member countries to avoid repeated lookups\"\"\"\n",
    "    return coco.CountryConverter().data[coco.CountryConverter().data['UNmember'].notna()]['ISO3'].dropna().tolist()\n",
    "\n",
    "@functools.lru_cache(maxsize=1000)\n",
    "def convert_country_code(country, target_format='UNnumeric'):\n",
    "    \"\"\"Cache country code conversions\"\"\"\n",
    "    return coco.convert(names=country, to=target_format, not_found=None)\n",
    "\n",
    "def create_data(edge_df, node_df, edge_country_a_col, edge_country_b_col, node_country_col, year_col=\"year\"):\n",
    "    \n",
    "    # Get UN countries once\n",
    "    uno_iso3_codes = get_un_countries()\n",
    "    \n",
    "    # Pre-filter dataframes more efficiently\n",
    "    edge_mask = edge_df[edge_country_a_col].isin(uno_iso3_codes) & edge_df[edge_country_b_col].isin(uno_iso3_codes)\n",
    "    node_mask = node_df[node_country_col].isin(uno_iso3_codes)\n",
    "    \n",
    "    edge_df = edge_df[edge_mask].copy()\n",
    "    node_df = node_df[node_mask].copy()\n",
    "    \n",
    "    print(f\"Number of edges after filtering: {len(edge_df)}\")\n",
    "    print(f\"Number of nodes after filtering: {len(node_df)}\")\n",
    "    \n",
    "    # Vectorized country code conversion (more efficient than individual conversions)\n",
    "    unique_countries_edges = pd.concat([edge_df[edge_country_a_col], edge_df[edge_country_b_col]]).unique()\n",
    "    unique_countries_nodes = node_df[node_country_col].unique()\n",
    "    all_unique_countries = np.unique(np.concatenate([unique_countries_edges, unique_countries_nodes]))\n",
    "    \n",
    "    # Single batch conversion\n",
    "    country_to_id_map = dict(zip(all_unique_countries, coco.convert(all_unique_countries.tolist(), to='UNnumeric', not_found=None)))\n",
    "    \n",
    "    # Apply mapping\n",
    "    edge_df['country_id_a'] = edge_df[edge_country_a_col].map(country_to_id_map)\n",
    "    edge_df['country_id_b'] = edge_df[edge_country_b_col].map(country_to_id_map)\n",
    "    node_df['country_id'] = node_df[node_country_col].map(country_to_id_map)\n",
    "    \n",
    "    node_df = node_df.sort_values(by='country_id')\n",
    "    \n",
    "    data_dict = {}\n",
    "    years = edge_df[year_col].unique()\n",
    "    \n",
    "    for year in years:        \n",
    "        # More efficient filtering\n",
    "        edge_year_mask = edge_df[year_col] == year\n",
    "        node_year_mask = node_df[year_col] == str(year)\n",
    "        \n",
    "        edge_df_year = edge_df[edge_year_mask]\n",
    "        node_df_year = node_df[node_year_mask]\n",
    "        \n",
    "        # Optimize feature processing\n",
    "        edge_features_cols = [col for col in edge_df_year.columns \n",
    "                             if col not in ['country_id_a', 'country_id_b', edge_country_a_col, edge_country_b_col, year_col]]\n",
    "        \n",
    "        edge_features_df = edge_df_year[edge_features_cols].fillna(0)\n",
    "        \n",
    "        # Convert boolean columns more efficiently\n",
    "        bool_cols = edge_features_df.select_dtypes(include='bool').columns\n",
    "        edge_features_df[bool_cols] = edge_features_df[bool_cols].astype(int)\n",
    "        \n",
    "        # Optimize node features processing\n",
    "        node_features_cols = [col for col in node_df_year.columns \n",
    "                             if col not in ['country_id', node_country_col, year_col]]\n",
    "        node_df_year_features = node_df_year[node_features_cols].copy()\n",
    "        \n",
    "        # Fix boolean column conversion to avoid FutureWarning\n",
    "        bool_cols_nodes = node_df_year_features.select_dtypes(include='bool').columns\n",
    "        if len(bool_cols_nodes) > 0:\n",
    "            # First convert the boolean columns to int dtype\n",
    "            for col in bool_cols_nodes:\n",
    "                node_df_year_features[col] = node_df_year_features[col].astype(int)\n",
    "\n",
    "        # More efficient tensor creation\n",
    "        edge_features_array = edge_features_df.values.astype(np.float32)\n",
    "        edge_attr = torch.from_numpy(edge_features_array)\n",
    "                \n",
    "        node_features = torch.tensor(node_df_year_features.values, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_df_year[['country_id_a', 'country_id_b']].values.T, dtype=torch.long)\n",
    "        \n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        data_dict[year] = data\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4930d2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "country_a",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_b",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "csl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lps",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "66920769-dfdd-4b38-a2da-911969e7cacc",
       "rows": [
        [
         "0",
         "ABW",
         "ABW",
         "1.6631225668608365",
         "0.2022843855473376"
        ],
        [
         "1",
         "ABW",
         "AFG",
         "0.021112971973526958",
         "0.15215704452562862"
        ],
        [
         "2",
         "ABW",
         "AGO",
         "0.0",
         "0.663155223169812"
        ],
        [
         "3",
         "ABW",
         "AIA",
         "0.4805826398978867",
         "0.3707875458303148"
        ],
        [
         "4",
         "ABW",
         "ALA",
         "0.0",
         "0.13592997287974118"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_a</th>\n",
       "      <th>country_b</th>\n",
       "      <th>csl</th>\n",
       "      <th>lps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1.663123</td>\n",
       "      <td>0.202284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AFG</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>0.152157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AGO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>AIA</td>\n",
       "      <td>0.480583</td>\n",
       "      <td>0.370788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ALA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_a country_b       csl       lps\n",
       "0       ABW       ABW  1.663123  0.202284\n",
       "1       ABW       AFG  0.021113  0.152157\n",
       "2       ABW       AGO  0.000000  0.663155\n",
       "3       ABW       AIA  0.480583  0.370788\n",
       "4       ABW       ALA  0.000000  0.135930"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lang_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "211b72f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges after filtering: 782920\n",
      "Number of nodes after filtering: 4402\n",
      "Number of edges after filtering: 54716\n",
      "Number of nodes after filtering: 2704\n",
      "Number of edges after filtering: 37249\n",
      "Number of nodes after filtering: 4186\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dlss_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# pol_data = create_data(df_pol_edges, df_pol_nodes,\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#                         edge_country_a_col='country_id_a', edge_country_b_col='country_id_b',\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#                         node_country_col='country_id', year_col='year')\u001b[39;00m\n\u001b[32m      9\u001b[39m cul_data = create_data(df_cult_edges, df_cult_nodes,\n\u001b[32m     10\u001b[39m                         edge_country_a_col=\u001b[33m'\u001b[39m\u001b[33mISO3_a\u001b[39m\u001b[33m'\u001b[39m, edge_country_b_col=\u001b[33m'\u001b[39m\u001b[33mISO3_b\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m                         node_country_col=\u001b[33m'\u001b[39m\u001b[33mISO3\u001b[39m\u001b[33m'\u001b[39m, year_col=\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m lang_data = \u001b[43mcreate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_lang_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_lang_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                        \u001b[49m\u001b[43medge_country_a_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcountry_a\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_country_b_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcountry_b\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mnode_country_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mISO3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcreate_data\u001b[39m\u001b[34m(edge_df, node_df, edge_country_a_col, edge_country_b_col, node_country_col, year_col)\u001b[39m\n\u001b[32m     40\u001b[39m node_df = node_df.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mcountry_id\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     42\u001b[39m data_dict = {}\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m years = \u001b[43medge_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43myear_col\u001b[49m\u001b[43m]\u001b[49m.unique()\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:        \n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# More efficient filtering\u001b[39;00m\n\u001b[32m     47\u001b[39m     edge_year_mask = edge_df[year_col] == year\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dlss_env/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dlss_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'year'"
     ]
    }
   ],
   "source": [
    "geo_data = create_data(df_geo_edges, df_geo_nodes, \n",
    "                        edge_country_a_col='iso_o', edge_country_b_col='iso_d',\n",
    "                        node_country_col='code_3', year_col='year')\n",
    "\n",
    "# pol_data = create_data(df_pol_edges, df_pol_nodes,\n",
    "#                         edge_country_a_col='country_id_a', edge_country_b_col='country_id_b',\n",
    "#                         node_country_col='country_id', year_col='year')\n",
    "\n",
    "cul_data = create_data(df_cult_edges, df_cult_nodes,\n",
    "                        edge_country_a_col='ISO3_a', edge_country_b_col='ISO3_b',\n",
    "                        node_country_col='ISO3', year_col='year')\n",
    "\n",
    "lang_data = create_data(df_lang_edges, df_lang_nodes,\n",
    "                        edge_country_a_col='country_a', edge_country_b_col='country_b',\n",
    "                        node_country_col='ISO3', year_col='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edb68a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(2000): Data(x=[189, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2001): Data(x=[189, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2002): Data(x=[189, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2003): Data(x=[189, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2004): Data(x=[189, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2005): Data(x=[189, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2006): Data(x=[191, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2007): Data(x=[191, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2008): Data(x=[191, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2009): Data(x=[191, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2010): Data(x=[191, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2011): Data(x=[191, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2012): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2013): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2014): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2015): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2016): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2017): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2018): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2019): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2020): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2021): Data(x=[193, 28], edge_index=[2, 34040], edge_attr=[34040, 16]),\n",
       " np.int64(2022): Data(x=[192, 28], edge_index=[2, 34040], edge_attr=[34040, 16])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlss)",
   "language": "python",
   "name": "dlss_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
