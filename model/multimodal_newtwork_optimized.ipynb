{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deeed32a",
   "metadata": {},
   "source": [
    "# Multimodal Network\n",
    "\n",
    "Create GNN for each of the dimensions and later combine them into a single network.\n",
    "\n",
    "1. Each dimension is a separate graph and gets its own GNN.\n",
    "2. Dimensions are connected in a MLP layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa47f5",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce967bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Current working directory: /home/jovyan/dlss-project\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import country_converter as coco\n",
    "import functools\n",
    "import os\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "# Set up device (is available use GPU to speed up computations)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "os.chdir('/home/jovyan/dlss-project')\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4987e0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38f27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_geo_edges = \"data_collection/geography/edges_yearly_dist_enc.parquet\"\n",
    "path_geo_nodes = \"data_collection/geography/nodes_enc.parquet\"\n",
    "df_geo_edges = pd.read_parquet(path_geo_edges)\n",
    "df_geo_nodes = pd.read_parquet(path_geo_nodes)\n",
    "\n",
    "path_pol_edges = \"data_collection/political/data/edge_features.parquet\"\n",
    "path_pol_nodes = \"data_collection/political/data/node_features.parquet\"\n",
    "df_pol_edges = pd.read_parquet(path_pol_edges)\n",
    "df_pol_nodes = pd.read_parquet(path_pol_nodes)\n",
    "\n",
    "path_cult_edges = \"data_collection/culture/culture_edges.parquet\"\n",
    "path_cult_nodes = \"data_collection/culture/culture_nodes.parquet\"\n",
    "df_cult_edges = pd.read_parquet(path_cult_edges)\n",
    "df_cult_nodes = pd.read_parquet(path_cult_nodes)\n",
    "\n",
    "path_lang_edges = \"data_collection/culture/language_religion_edges.parquet\"\n",
    "path_lang_nodes = \"data_collection/culture/language_religion_nodes.parquet\"\n",
    "df_lang_edges = pd.read_parquet(path_lang_edges)\n",
    "df_lang_nodes = pd.read_parquet(path_lang_nodes)\n",
    "\n",
    "path_eco_edges = \"data_collection/economics/edges_economics.parquet\"\n",
    "path_eco_nodes = \"data_collection/economics/nodes_economics.parquet\"\n",
    "df_eco_edges = pd.read_parquet(path_eco_edges)\n",
    "df_eco_nodes = pd.read_parquet(path_eco_nodes)\n",
    "\n",
    "path_gini = \"data_collection/gini.parquet\"\n",
    "df_gini = pd.read_parquet(path_gini)\n",
    "df_gini = df_gini[df_gini['year'].between(2000, 2022)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfe5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute UN member countries once\n",
    "@functools.lru_cache(maxsize=1)\n",
    "def get_un_countries():\n",
    "    \"\"\"Cache UN member countries to avoid repeated lookups\"\"\"\n",
    "    iso3 = coco.CountryConverter().data[coco.CountryConverter().data['UNmember'].notna()]['ISO3'].dropna().tolist()\n",
    "    unnumeric = coco.CountryConverter().data[coco.CountryConverter().data['UNmember'].notna()]['UNcode'].dropna().tolist()\n",
    "    return iso3, unnumeric\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=1000)\n",
    "def convert_country_code(country, target_format='UNnumeric'):\n",
    "    \"\"\"Cache country code conversions\"\"\"\n",
    "    return coco.convert(names=country, to=target_format, not_found=None)\n",
    "\n",
    "def create_data(edge_df, node_df, edge_country_a_col, edge_country_b_col, node_country_col, year_col=\"year\"):\n",
    "    # Get UN countries once\n",
    "    uno_iso3_codes, uno_unnumeric_codes = get_un_countries()\n",
    "\n",
    "    # Pre-filter dataframes\n",
    "    edge_mask = edge_df[edge_country_a_col].isin(uno_iso3_codes) & edge_df[edge_country_b_col].isin(uno_iso3_codes)\n",
    "    node_mask = node_df[node_country_col].isin(uno_iso3_codes)\n",
    "\n",
    "    edge_df = edge_df[edge_mask].copy()\n",
    "    node_df = node_df[node_mask].copy()\n",
    "\n",
    "    # Ensure year is int before unique extraction\n",
    "    edge_df[year_col] = edge_df[year_col].astype(int)\n",
    "    node_df[year_col] = node_df[year_col].astype(int)\n",
    "\n",
    "    print(f\"Number of edges after filtering: {len(edge_df)}\")\n",
    "    print(f\"Number of nodes after filtering: {len(node_df)}\")\n",
    "\n",
    "    # Vectorized country code conversion\n",
    "    unique_countries_edges = pd.concat([edge_df[edge_country_a_col], edge_df[edge_country_b_col]]).unique()\n",
    "    unique_countries_nodes = node_df[node_country_col].unique()\n",
    "    all_unique_countries = np.unique(np.concatenate([unique_countries_edges, unique_countries_nodes]))\n",
    "\n",
    "    country_to_id_map = dict(zip(\n",
    "        all_unique_countries,\n",
    "        coco.convert(all_unique_countries.tolist(), to='UNnumeric', not_found=None)\n",
    "    ))\n",
    "\n",
    "    # Apply mapping\n",
    "    edge_df['country_id_a'] = edge_df[edge_country_a_col].map(country_to_id_map)\n",
    "    edge_df['country_id_b'] = edge_df[edge_country_b_col].map(country_to_id_map)\n",
    "    node_df['country_id'] = node_df[node_country_col].map(country_to_id_map)\n",
    "\n",
    "    # Drop any rows where mapping failed (shouldn't if filters were correct)\n",
    "    edge_df = edge_df.dropna(subset=['country_id_a', 'country_id_b'])\n",
    "    node_df = node_df.dropna(subset=['country_id'])\n",
    "\n",
    "    # Cast country_id to int\n",
    "    edge_df['country_id_a'] = edge_df['country_id_a'].astype(int)\n",
    "    edge_df['country_id_b'] = edge_df['country_id_b'].astype(int)\n",
    "    node_df['country_id'] = node_df['country_id'].astype(int)\n",
    "    \n",
    "    # --- Standardize edge features ---\n",
    "    edge_features_cols = [\n",
    "        col for col in edge_df.columns\n",
    "        if col not in [edge_country_a_col, edge_country_b_col, year_col, 'country_id_a', 'country_id_b']\n",
    "    ]\n",
    "    if edge_features_cols:\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_df[edge_features_cols] = edge_scaler.fit_transform(edge_df[edge_features_cols])\n",
    "\n",
    "    # --- Standardize node features ---\n",
    "    node_features_cols = [\n",
    "        col for col in node_df.columns\n",
    "        if col not in [node_country_col, year_col, 'country_id']\n",
    "    ]\n",
    "    if node_features_cols:\n",
    "        node_scaler = StandardScaler()\n",
    "        node_df[node_features_cols] = node_scaler.fit_transform(node_df[node_features_cols])\n",
    "    \n",
    "    \n",
    "\n",
    "    data_dict = {}\n",
    "    years = edge_df[year_col].unique()\n",
    "    \n",
    "    # limit years from 2000 to 2022\n",
    "    years = [year for year in years if 2000 <= year <= 2022]\n",
    "\n",
    "    for year in years:\n",
    "        edge_df_year = edge_df[edge_df[year_col] == year]\n",
    "        node_df_year = node_df[node_df[year_col] == year].copy()  # copy because we'll potentially modify\n",
    "        \n",
    "        # drop dupicate rows in node_df_year\n",
    "        node_df_year = node_df_year.drop_duplicates(subset=['country_id', year_col], keep='first')\n",
    "                \n",
    "        # --- Edge features ---\n",
    "        edge_features_cols = [\n",
    "            col for col in edge_df_year.columns\n",
    "            if col not in ['country_id_a', 'country_id_b', edge_country_a_col, edge_country_b_col, year_col]\n",
    "        ]\n",
    "        edge_features_df = edge_df_year[edge_features_cols].copy()\n",
    "\n",
    "        # Boolean to int\n",
    "        bool_cols_edges = edge_features_df.select_dtypes(include='bool').columns\n",
    "        if len(bool_cols_edges) > 0:\n",
    "            edge_features_df[bool_cols_edges] = edge_features_df[bool_cols_edges].astype(int)\n",
    "\n",
    "        # Coerce all edge feature columns to numeric, fill NaN with 0\n",
    "        edge_features_df = edge_features_df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "        # --- Node features ---\n",
    "        node_features_cols = [\n",
    "            col for col in node_df_year.columns\n",
    "            if col not in ['country_id', node_country_col, year_col]\n",
    "        ]\n",
    "\n",
    "        # Add missing countries (so each year has all UN countries)\n",
    "        existing_countries = set(node_df_year['country_id'])\n",
    "        missing_countries = set(uno_unnumeric_codes) - existing_countries\n",
    "        \n",
    "        # Boolean to int for node features\n",
    "        bool_cols_nodes = node_df_year.select_dtypes(include='bool').columns\n",
    "        if len(bool_cols_nodes) > 0:\n",
    "            node_df_year[bool_cols_nodes] = node_df_year[bool_cols_nodes].astype(int)\n",
    "            \n",
    "        # add column to state if country does exist in this year/dataset\n",
    "        node_df_year['exists'] = 1\n",
    "\n",
    "        if missing_countries:\n",
    "            # Build missing rows once\n",
    "            for country in missing_countries:\n",
    "                missing_row = {col: 0 for col in node_features_cols}\n",
    "                missing_row['country_id'] = country\n",
    "                missing_row['year'] = year\n",
    "                missing_row['exists'] = 0\n",
    "                row_df = pd.DataFrame([missing_row])\n",
    "                node_df_year = pd.concat([node_df_year, row_df], ignore_index=True)\n",
    "\n",
    "        # Ensure node_df_year is sorted by country_id and align features accordingly\n",
    "        node_df_year_sorted = node_df_year.sort_values(by='country_id').reset_index(drop=True)\n",
    "        \n",
    "        # select only feature columns\n",
    "        node_df_year_features = node_df_year_sorted[node_features_cols].copy()\n",
    "        \n",
    "        country_id_tensor = torch.tensor(node_df_year_sorted['country_id'].values, dtype=torch.long)\n",
    "\n",
    "        # --- Tensor creation ---\n",
    "        edge_features_array = edge_features_df.values.astype(np.float32)\n",
    "        edge_attr = torch.from_numpy(edge_features_array)\n",
    "\n",
    "        node_features_tensor = torch.tensor(node_df_year_features.values, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "        # Build a mapping from country_id to its position in the sorted node list\n",
    "        country_id_to_pos = {cid: i for i, cid in enumerate(node_df_year_sorted['country_id'].values)}\n",
    "\n",
    "        # Map edge indices to positions in the sorted node list\n",
    "        edge_index = torch.tensor(\n",
    "            [\n",
    "            edge_df_year['country_id_a'].map(country_id_to_pos).values,\n",
    "            edge_df_year['country_id_b'].map(country_id_to_pos).values\n",
    "            ],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        data = Data(x=node_features_tensor, edge_index=edge_index, edge_attr=edge_attr, country_id = country_id_tensor)\n",
    "        data_dict[year] = data\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def create_gini_data(df_gini, year_col='year', country_col='country', gini_col='gini'):\n",
    "    # Get UN countries once\n",
    "    uno_iso3_codes, uno_unnumeric_codes = get_un_countries()\n",
    "\n",
    "    # Filter Gini data for UN countries\n",
    "    df_gini = df_gini[df_gini[country_col].isin(uno_iso3_codes)].copy()\n",
    "    \n",
    "    # Convert country codes to UN numeric\n",
    "    df_gini['country_id'] = df_gini[country_col].map(lambda x: convert_country_code(x, 'UNnumeric'))\n",
    "    \n",
    "    df_gini = df_gini.sort_values(by=['country_id']).reset_index(drop=True)\n",
    "    \n",
    "    # Drop rows with NaN country_id\n",
    "    df_gini = df_gini.dropna(subset=['country_id'])\n",
    "    \n",
    "    # Normalize Gini values to [0, 1] range for each year\n",
    "    df_gini[gini_col] = df_gini[gini_col] / 100\n",
    "    \n",
    "    # create mask column to indicate if country exists in this year\n",
    "    df_gini['exists'] = 1\n",
    "    df_gini.loc[df_gini[gini_col].isna(), 'exists'] = 0\n",
    "    \n",
    "    df_gini.loc[df_gini[gini_col].isna(), gini_col] = 0  # Fill NaN Gini values with 0\n",
    "    \n",
    "    # for each year, create a Data object\n",
    "    gini_data_dict = {}\n",
    "    years = df_gini[year_col].unique()\n",
    "    for year in years:\n",
    "        df_year = df_gini[df_gini[year_col] == year].copy()\n",
    "        \n",
    "        # Ensure country_id is int\n",
    "        df_year['country_id'] = df_year['country_id'].astype(int)\n",
    "        \n",
    "        # Create tensor for Gini values\n",
    "        gini_tensor = torch.tensor(df_year[gini_col].values, dtype=torch.float32)\n",
    "        \n",
    "        # Create tensor for country IDs\n",
    "        country_id_tensor = torch.tensor(df_year['country_id'].values, dtype=torch.long)\n",
    "        \n",
    "        # Create Data object\n",
    "        data = Data(y=gini_tensor.unsqueeze(1), country_id=country_id_tensor, exists=df_year['exists'].values)\n",
    "        gini_data_dict[year] = data\n",
    "    return gini_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211b72f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges after filtering: 782920\n",
      "Number of nodes after filtering: 4402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_523/893950086.py:152: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  edge_index = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges after filtering: 28818\n",
      "Number of nodes after filtering: 3785\n",
      "Number of edges after filtering: 180250\n",
      "Number of nodes after filtering: 2548\n",
      "Number of edges after filtering: 852288\n",
      "Number of nodes after filtering: 4186\n",
      "Number of edges after filtering: 589247\n",
      "Number of nodes after filtering: 4393\n"
     ]
    }
   ],
   "source": [
    "geo_data = create_data(df_geo_edges, df_geo_nodes, \n",
    "                        edge_country_a_col='iso_o', edge_country_b_col='iso_d',\n",
    "                        node_country_col='code_3', year_col='year')\n",
    "\n",
    "pol_data = create_data(df_pol_edges, df_pol_nodes,\n",
    "                        edge_country_a_col='state1', edge_country_b_col='state2',\n",
    "                        node_country_col='country', year_col='year')\n",
    "\n",
    "cul_data = create_data(df_cult_edges, df_cult_nodes,\n",
    "                        edge_country_a_col='ISO3_a', edge_country_b_col='ISO3_b',\n",
    "                        node_country_col='ISO3', year_col='year')\n",
    "\n",
    "lang_data = create_data(df_lang_edges, df_lang_nodes,\n",
    "                        edge_country_a_col='country_a', edge_country_b_col='country_b',\n",
    "                        node_country_col='ISO3', year_col='year')\n",
    "\n",
    "eco_data = create_data(df_eco_edges, df_eco_nodes,\n",
    "                        edge_country_a_col='src_ISO3', edge_country_b_col='tgt_ISO3',\n",
    "                        node_country_col='ISO3', year_col='year')\n",
    "\n",
    "gini_data = create_gini_data(df_gini, year_col='year', country_col='country', gini_col='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb82dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_years = {}\n",
    "\n",
    "for year in geo_data.keys():\n",
    "    network_data = {\n",
    "        'geography': geo_data[year],\n",
    "        'political': pol_data[year] if 'pol_data' in locals() else None,\n",
    "        'culture': cul_data[year],\n",
    "        'language': lang_data[year] if 'lang_data' in locals() else None,\n",
    "        'economy': eco_data[year],  # Placeholder for future economy data\n",
    "        'GINI': gini_data[year]  # Placeholder for GINI data\n",
    "    }\n",
    "    data_years[year] = network_data\n",
    "    \n",
    "# get the dimesions of each network: number of node_features, number of edge-features\n",
    "network_dimesions = {\n",
    "    'geography': {\n",
    "        'node_features': geo_data[2000].x.shape[1],\n",
    "        'edge_features': geo_data[2000].edge_attr.shape[1]\n",
    "    },\n",
    "    'political': {\n",
    "        'node_features': pol_data[2000].x.shape[1],\n",
    "        'edge_features': pol_data[2000].edge_attr.shape[1]\n",
    "    } if 'pol_data' in locals() else None,\n",
    "    'culture': {\n",
    "        'node_features': cul_data[2000].x.shape[1],\n",
    "        'edge_features': cul_data[2000].edge_attr.shape[1]\n",
    "    },\n",
    "    'language': {\n",
    "        'node_features': lang_data[2000].x.shape[1],\n",
    "        'edge_features': lang_data[2000].edge_attr.shape[1]\n",
    "    } if 'lang_data' in locals() else None,\n",
    "    'economy': {\n",
    "        'node_features': eco_data[2000].x.shape[1],\n",
    "        'edge_features': eco_data[2000].edge_attr.shape[1]\n",
    "        },  # Placeholder for future economy data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de174902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train years: 13\n",
      "Validation years: 5\n",
      "Test years: 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_years = sorted(data_years.keys())\n",
    "train_years, test_years = train_test_split(all_years, test_size=0.2, random_state=42)\n",
    "train_years, val_years = train_test_split(train_years, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "train_set = [data_years[year] for year in train_years]\n",
    "val_set = [data_years[year] for year in val_years]\n",
    "test_set = [data_years[year] for year in test_years]\n",
    "\n",
    "print(\"Train years:\", len(train_set))\n",
    "print(\"Validation years:\", len(val_set))\n",
    "print(\"Test years:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc086f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geography': {'node_features': 28, 'edge_features': 16},\n",
       " 'political': {'node_features': 7, 'edge_features': 5},\n",
       " 'culture': {'node_features': 6, 'edge_features': 11},\n",
       " 'language': {'node_features': 7, 'edge_features': 2},\n",
       " 'economy': {'node_features': 3, 'edge_features': 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_dimesions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd1a42",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe56378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GNN model for each of the different networks\n",
    "# class DimensionModel(torch.nn.Module):\n",
    "#     def __init__(self, num_node_features, num_edge_features, hidden_size=64, target_size=1):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_node_features = num_node_features\n",
    "#         self.num_edge_features = num_edge_features\n",
    "#         self.target_size = target_size\n",
    "#         self.convs = nn.ModuleList([GATv2Conv(self.num_node_features, self.hidden_size, edge_dim = num_edge_features),\n",
    "#                       GATv2Conv(self.hidden_size, self.hidden_size, edge_dim = num_edge_features)])\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "#         for conv in self.convs[:-1]:\n",
    "#             x = conv(x, edge_index, edge_attr=edge_attr) # adding edge features here!\n",
    "#             x = F.relu(x)\n",
    "#             x = F.dropout(x, training=self.training)\n",
    "#         x = self.convs[-1](x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "#         return x\n",
    "    \n",
    "# class MultiModalGNNModel(nn.Module):\n",
    "#     def __init__(self, \n",
    "#                  input_dims,  # list of (num_node_features, num_edge_features) per modality\n",
    "#                  hidden_size=32,\n",
    "#                  final_output_size=1):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.geo_model = DimensionModel(input_dims['geography']['node_features'], \n",
    "#                                         input_dims['geography']['edge_features'], hidden_size)\n",
    "#         self.pol_model = DimensionModel(input_dims['political']['node_features'], \n",
    "#                                         input_dims['political']['edge_features'], hidden_size)\n",
    "#         self.cult_model = DimensionModel(input_dims['culture']['node_features'], \n",
    "#                                         input_dims['culture']['edge_features'], hidden_size)\n",
    "#         self.lang_model = DimensionModel(input_dims['language']['node_features'], \n",
    "#                                         input_dims['language']['edge_features'], hidden_size)\n",
    "#         self.eco_model = DimensionModel(input_dims['economy']['node_features'], \n",
    "#                                         input_dims['economy']['edge_features'], hidden_size)\n",
    "\n",
    "#         self.fusion_input_size = hidden_size * len(input_dims.keys())\n",
    "\n",
    "#         self.mlp = nn.Sequential(\n",
    "#             nn.Linear(self.fusion_input_size, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, final_output_size)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, data_dict):\n",
    "#         geo_emb = self.geo_model(data_dict['geography'])\n",
    "#         pol_emb = self.pol_model(data_dict['political'])\n",
    "#         cult_emb = self.cult_model(data_dict['culture'])\n",
    "#         lang_emb = self.lang_model(data_dict['language'])\n",
    "#         eco_emb = self.eco_model(data_dict['economy'])\n",
    "        \n",
    "#         embeddings = [geo_emb, pol_emb, cult_emb, lang_emb, eco_emb]\n",
    "\n",
    "#         fused = torch.cat(embeddings, dim=-1)  # shape: [num_nodes, hidden_size * num_modalities]\n",
    "#         output = self.mlp(fused)               # shape: [num_nodes, final_output_size]\n",
    "#         return output\n",
    "\n",
    "# TODO: for each network model, for each country add 0/1 label to state if country is missing or not\n",
    "\n",
    "\n",
    "# GNN model for each of the different networks\n",
    "class DimensionModel(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, hidden_size=64, target_size=1, n_gat_layers=2, n_mlp_layers=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.target_size = target_size\n",
    "        # Dynamically create GAT layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GATv2Conv(self.num_node_features, self.hidden_size, edge_dim=num_edge_features))\n",
    "        for _ in range(n_gat_layers - 1):\n",
    "            self.convs.append(GATv2Conv(self.hidden_size, self.hidden_size, edge_dim=num_edge_features))\n",
    "\n",
    "        # Dynamically create MLP layers\n",
    "        self.n_mlp_layers = n_mlp_layers\n",
    "        mlp_layers = []\n",
    "        for _ in range(n_mlp_layers):\n",
    "            mlp_layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(0.2))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr=edge_attr)\n",
    "        if self.n_mlp_layers > 0:\n",
    "            x = self.mlp(x)  # Apply the fully connected layer\n",
    "        return x\n",
    "    \n",
    "class MultiModalGNNModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dims,\n",
    "                 hidden_size=64,\n",
    "                 final_output_size=1, \n",
    "                 n_gat_layers=2,\n",
    "                 n_dim_mlp_layers=2,\n",
    "                 combination_method='concat',\n",
    "                 mlp_variant='default'):\n",
    "        super().__init__()\n",
    "        self.combination_method = combination_method\n",
    "\n",
    "        self.geo_model = DimensionModel(input_dims['geography']['node_features'], input_dims['geography']['edge_features'], hidden_size, n_gat_layers=n_gat_layers, n_mlp_layers=n_dim_mlp_layers)\n",
    "        self.pol_model = DimensionModel(input_dims['political']['node_features'], input_dims['political']['edge_features'], hidden_size, n_gat_layers=n_gat_layers, n_mlp_layers=n_dim_mlp_layers)\n",
    "        self.cult_model = DimensionModel(input_dims['culture']['node_features'], input_dims['culture']['edge_features'], hidden_size, n_gat_layers=n_gat_layers, n_mlp_layers=n_dim_mlp_layers)\n",
    "        self.lang_model = DimensionModel(input_dims['language']['node_features'], input_dims['language']['edge_features'], hidden_size, n_gat_layers=n_gat_layers, n_mlp_layers=n_dim_mlp_layers)\n",
    "        self.eco_model = DimensionModel(input_dims['economy']['node_features'], input_dims['economy']['edge_features'], hidden_size, n_gat_layers=n_gat_layers, n_mlp_layers=n_dim_mlp_layers)\n",
    "\n",
    "        self.num_modalities = 5\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.combination_method == 'attention':\n",
    "            # Learnable attention weights for each modality\n",
    "            self.attn_weights = nn.Parameter(torch.ones(self.num_modalities))\n",
    "\n",
    "        self.fusion_input_size = hidden_size * self.num_modalities if combination_method == 'concat' else hidden_size\n",
    "        if mlp_variant == 'default':\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(self.fusion_input_size, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, final_output_size)\n",
    "            )\n",
    "        elif mlp_variant == 'deep':\n",
    "            # Deeper MLP variant\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(self.fusion_input_size, 2048),\n",
    "                nn.BatchNorm1d(2048),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, final_output_size)\n",
    "            )\n",
    "        elif mlp_variant == 'shallow':\n",
    "            # Shallow MLP variant\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(self.fusion_input_size, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, final_output_size)\n",
    "            )        \n",
    "    \n",
    "\n",
    "    def forward(self, data_dict):\n",
    "        geo_emb = self.geo_model(data_dict['geography'])\n",
    "        pol_emb = self.pol_model(data_dict['political'])\n",
    "        cult_emb = self.cult_model(data_dict['culture'])\n",
    "        lang_emb = self.lang_model(data_dict['language'])\n",
    "        eco_emb = self.eco_model(data_dict['economy'])\n",
    "\n",
    "        embeddings = [geo_emb, pol_emb, cult_emb, lang_emb, eco_emb]\n",
    "\n",
    "        if self.combination_method == 'concat':\n",
    "            # Concatenate embeddings along the last dimension\n",
    "            fused = torch.cat(embeddings, dim=-1)\n",
    "        elif self.combination_method == 'attention':\n",
    "            # Stack embeddings: shape [num_nodes, num_modalities, hidden_size]\n",
    "            stacked = torch.stack(embeddings, dim=1)  # [num_nodes, num_modalities, hidden_size]\n",
    "            attn = torch.softmax(self.attn_weights, dim=0)  # [num_modalities]\n",
    "            attn = attn.view(1, self.num_modalities, 1)     # [1, num_modalities, 1] for broadcasting\n",
    "            fused = (stacked * attn).sum(dim=1)             # [num_nodes, hidden_size]\n",
    "        output = self.mlp(fused)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411cb44",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "190903ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=25, min_delta=0.0001, path='checkpoint.pt', printing=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.path = path  # Path to save the best model\n",
    "        self.printing = printing\n",
    "        \n",
    "        # remove model if path already exists\n",
    "        if os.path.exists(path):\n",
    "          os.remove(path)\n",
    "          if self.printing:\n",
    "            print(f\"Removing existing model at: {path}\")\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if val_loss < self.best_loss:\n",
    "                self.save_checkpoint(val_loss, model)\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        if self.printing:\n",
    "            print(f'Validation loss decreased ({self.best_loss:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        \n",
    "        \n",
    "def train_gnn(epochs, model, optimizer, criterion, train_loader, val_loader, early_stopper, printing=True):    \n",
    "    # Make sure device is defined\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move the data and model to the device\n",
    "    # data_dict = move_data_to_device(data_dict, device)\n",
    "\n",
    "    # model = model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    if printing:\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_temp = 0\n",
    "        for data_dict in train_loader:\n",
    "            # Training\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass on the entire graph\n",
    "            output = model(data_dict)\n",
    "            mask = torch.tensor(data_dict['GINI'].exists, dtype=torch.bool, device=output.device).flatten()\n",
    "            target = data_dict['GINI'].y\n",
    "\n",
    "            # Calculate loss using only valid entries\n",
    "            train_loss = criterion(output[mask], target[mask])\n",
    "\n",
    "            # Backward pass\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_temp += train_loss.item()\n",
    "\n",
    "        train_losses.append(train_loss_temp / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_temp = 0\n",
    "        with torch.no_grad():\n",
    "            for data_dict in val_loader:\n",
    "                output = model(data_dict)\n",
    "                mask = torch.tensor(data_dict['GINI'].exists, dtype=torch.bool, device=output.device).flatten()\n",
    "                target = data_dict['GINI'].y\n",
    "                val_loss = criterion(output[mask], target[mask])\n",
    "                val_loss_temp += val_loss.item()\n",
    "        val_losses.append(val_loss_temp / len(val_loader))\n",
    "        if printing:\n",
    "            print(f'Epoch: {epoch+1}, Training Loss: {train_loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        early_stopper(val_loss, model)\n",
    "        if early_stopper.early_stop:\n",
    "            if printing:\n",
    "                print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(torch.load(early_stopper.path))\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e213e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "545939c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def move_data_dict_to_device(data_dict, device):\n",
    "    moved = {}\n",
    "    for k, v in data_dict.items():\n",
    "        if hasattr(v, 'to'):\n",
    "            moved[k] = v.to(device)\n",
    "        else:\n",
    "            moved[k] = v\n",
    "    return moved\n",
    "\n",
    "train_set = [move_data_dict_to_device(d, device) for d in train_set]\n",
    "val_set = [move_data_dict_to_device(d, device) for d in val_set]\n",
    "test_set = [move_data_dict_to_device(d, device) for d in test_set]\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "991c49a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing model at: model_checkpoints/gan_checkpoint.pt\n",
      "Starting training...\n",
      "Epoch: 1, Training Loss: 0.3016, Validation Loss: 0.3423\n",
      "Validation loss decreased (0.342280 --> 0.342280).  Saving model ...\n",
      "Epoch: 2, Training Loss: 0.3027, Validation Loss: 0.3370\n",
      "Validation loss decreased (0.342280 --> 0.336974).  Saving model ...\n",
      "Epoch: 3, Training Loss: 0.3082, Validation Loss: 0.3317\n",
      "Validation loss decreased (0.336974 --> 0.331679).  Saving model ...\n",
      "Epoch: 4, Training Loss: 0.3000, Validation Loss: 0.3263\n",
      "Validation loss decreased (0.331679 --> 0.326289).  Saving model ...\n",
      "Epoch: 5, Training Loss: 0.2941, Validation Loss: 0.3207\n",
      "Validation loss decreased (0.326289 --> 0.320701).  Saving model ...\n",
      "Epoch: 6, Training Loss: 0.2728, Validation Loss: 0.3149\n",
      "Validation loss decreased (0.320701 --> 0.314886).  Saving model ...\n",
      "Epoch: 7, Training Loss: 0.2843, Validation Loss: 0.3088\n",
      "Validation loss decreased (0.314886 --> 0.308769).  Saving model ...\n",
      "Epoch: 8, Training Loss: 0.2630, Validation Loss: 0.3021\n",
      "Validation loss decreased (0.308769 --> 0.302112).  Saving model ...\n",
      "Epoch: 9, Training Loss: 0.2609, Validation Loss: 0.2948\n",
      "Validation loss decreased (0.302112 --> 0.294829).  Saving model ...\n",
      "Epoch: 10, Training Loss: 0.2591, Validation Loss: 0.2868\n",
      "Validation loss decreased (0.294829 --> 0.286836).  Saving model ...\n",
      "Epoch: 11, Training Loss: 0.2393, Validation Loss: 0.2781\n",
      "Validation loss decreased (0.286836 --> 0.278082).  Saving model ...\n",
      "Epoch: 12, Training Loss: 0.2394, Validation Loss: 0.2686\n",
      "Validation loss decreased (0.278082 --> 0.268612).  Saving model ...\n",
      "Epoch: 13, Training Loss: 0.2321, Validation Loss: 0.2584\n",
      "Validation loss decreased (0.268612 --> 0.258369).  Saving model ...\n",
      "Epoch: 14, Training Loss: 0.2543, Validation Loss: 0.2471\n",
      "Validation loss decreased (0.258369 --> 0.247117).  Saving model ...\n",
      "Epoch: 15, Training Loss: 0.1894, Validation Loss: 0.2345\n",
      "Validation loss decreased (0.247117 --> 0.234458).  Saving model ...\n",
      "Epoch: 16, Training Loss: 0.1718, Validation Loss: 0.2201\n",
      "Validation loss decreased (0.234458 --> 0.220096).  Saving model ...\n",
      "Epoch: 17, Training Loss: 0.1609, Validation Loss: 0.2033\n",
      "Validation loss decreased (0.220096 --> 0.203278).  Saving model ...\n",
      "Epoch: 18, Training Loss: 0.1647, Validation Loss: 0.1832\n",
      "Validation loss decreased (0.203278 --> 0.183231).  Saving model ...\n",
      "Epoch: 19, Training Loss: 0.1490, Validation Loss: 0.1623\n",
      "Validation loss decreased (0.183231 --> 0.162269).  Saving model ...\n",
      "Epoch: 20, Training Loss: 0.1396, Validation Loss: 0.1426\n",
      "Validation loss decreased (0.162269 --> 0.142588).  Saving model ...\n",
      "Epoch: 21, Training Loss: 0.1085, Validation Loss: 0.1263\n",
      "Validation loss decreased (0.142588 --> 0.126311).  Saving model ...\n",
      "Epoch: 22, Training Loss: 0.0938, Validation Loss: 0.1153\n",
      "Validation loss decreased (0.126311 --> 0.115290).  Saving model ...\n",
      "Epoch: 23, Training Loss: 0.0724, Validation Loss: 0.1080\n",
      "Validation loss decreased (0.115290 --> 0.107968).  Saving model ...\n",
      "Epoch: 24, Training Loss: 0.0860, Validation Loss: 0.1024\n",
      "Validation loss decreased (0.107968 --> 0.102398).  Saving model ...\n",
      "Epoch: 25, Training Loss: 0.0737, Validation Loss: 0.0981\n",
      "Validation loss decreased (0.102398 --> 0.098087).  Saving model ...\n",
      "Epoch: 26, Training Loss: 0.0662, Validation Loss: 0.0948\n",
      "Validation loss decreased (0.098087 --> 0.094793).  Saving model ...\n",
      "Epoch: 27, Training Loss: 0.0933, Validation Loss: 0.0927\n",
      "Validation loss decreased (0.094793 --> 0.092734).  Saving model ...\n",
      "Epoch: 28, Training Loss: 0.0953, Validation Loss: 0.0908\n",
      "Validation loss decreased (0.092734 --> 0.090761).  Saving model ...\n",
      "Epoch: 29, Training Loss: 0.0754, Validation Loss: 0.0891\n",
      "Validation loss decreased (0.090761 --> 0.089144).  Saving model ...\n",
      "Epoch: 30, Training Loss: 0.0627, Validation Loss: 0.0874\n",
      "Validation loss decreased (0.089144 --> 0.087407).  Saving model ...\n",
      "Epoch: 31, Training Loss: 0.0655, Validation Loss: 0.0861\n",
      "Validation loss decreased (0.087407 --> 0.086087).  Saving model ...\n",
      "Epoch: 32, Training Loss: 0.0645, Validation Loss: 0.0849\n",
      "Validation loss decreased (0.086087 --> 0.084852).  Saving model ...\n",
      "Epoch: 33, Training Loss: 0.0711, Validation Loss: 0.0838\n",
      "Validation loss decreased (0.084852 --> 0.083765).  Saving model ...\n",
      "Epoch: 34, Training Loss: 0.0547, Validation Loss: 0.0822\n",
      "Validation loss decreased (0.083765 --> 0.082232).  Saving model ...\n",
      "Epoch: 35, Training Loss: 0.0666, Validation Loss: 0.0813\n",
      "Validation loss decreased (0.082232 --> 0.081303).  Saving model ...\n",
      "Epoch: 36, Training Loss: 0.0603, Validation Loss: 0.0803\n",
      "Validation loss decreased (0.081303 --> 0.080282).  Saving model ...\n",
      "Epoch: 37, Training Loss: 0.0610, Validation Loss: 0.0796\n",
      "Validation loss decreased (0.080282 --> 0.079633).  Saving model ...\n",
      "Epoch: 38, Training Loss: 0.0657, Validation Loss: 0.0790\n",
      "Validation loss decreased (0.079633 --> 0.078999).  Saving model ...\n",
      "Epoch: 39, Training Loss: 0.0744, Validation Loss: 0.0781\n",
      "Validation loss decreased (0.078999 --> 0.078077).  Saving model ...\n",
      "Epoch: 40, Training Loss: 0.0647, Validation Loss: 0.0774\n",
      "Validation loss decreased (0.078077 --> 0.077363).  Saving model ...\n",
      "Epoch: 41, Training Loss: 0.0586, Validation Loss: 0.0767\n",
      "Validation loss decreased (0.077363 --> 0.076664).  Saving model ...\n",
      "Epoch: 42, Training Loss: 0.0576, Validation Loss: 0.0757\n",
      "Validation loss decreased (0.076664 --> 0.075728).  Saving model ...\n",
      "Epoch: 43, Training Loss: 0.0495, Validation Loss: 0.0754\n",
      "Validation loss decreased (0.075728 --> 0.075355).  Saving model ...\n",
      "Epoch: 44, Training Loss: 0.0678, Validation Loss: 0.0747\n",
      "Validation loss decreased (0.075355 --> 0.074653).  Saving model ...\n",
      "Epoch: 45, Training Loss: 0.0482, Validation Loss: 0.0737\n",
      "Validation loss decreased (0.074653 --> 0.073681).  Saving model ...\n",
      "Epoch: 46, Training Loss: 0.0548, Validation Loss: 0.0726\n",
      "Validation loss decreased (0.073681 --> 0.072638).  Saving model ...\n",
      "Epoch: 47, Training Loss: 0.0519, Validation Loss: 0.0717\n",
      "Validation loss decreased (0.072638 --> 0.071746).  Saving model ...\n",
      "Epoch: 48, Training Loss: 0.0562, Validation Loss: 0.0703\n",
      "Validation loss decreased (0.071746 --> 0.070302).  Saving model ...\n",
      "Epoch: 49, Training Loss: 0.0621, Validation Loss: 0.0701\n",
      "Validation loss decreased (0.070302 --> 0.070134).  Saving model ...\n",
      "Epoch: 50, Training Loss: 0.0523, Validation Loss: 0.0702\n",
      "Epoch: 51, Training Loss: 0.0760, Validation Loss: 0.0702\n",
      "Epoch: 52, Training Loss: 0.0520, Validation Loss: 0.0683\n",
      "Validation loss decreased (0.070134 --> 0.068280).  Saving model ...\n",
      "Epoch: 53, Training Loss: 0.0505, Validation Loss: 0.0678\n",
      "Validation loss decreased (0.068280 --> 0.067795).  Saving model ...\n",
      "Epoch: 54, Training Loss: 0.0463, Validation Loss: 0.0681\n",
      "Epoch: 55, Training Loss: 0.0474, Validation Loss: 0.0680\n",
      "Epoch: 56, Training Loss: 0.0504, Validation Loss: 0.0683\n",
      "Epoch: 57, Training Loss: 0.0465, Validation Loss: 0.0668\n",
      "Validation loss decreased (0.067795 --> 0.066845).  Saving model ...\n",
      "Epoch: 58, Training Loss: 0.0647, Validation Loss: 0.0680\n",
      "Epoch: 59, Training Loss: 0.0523, Validation Loss: 0.0674\n",
      "Epoch: 60, Training Loss: 0.0571, Validation Loss: 0.0660\n",
      "Validation loss decreased (0.066845 --> 0.065967).  Saving model ...\n",
      "Epoch: 61, Training Loss: 0.0541, Validation Loss: 0.0653\n",
      "Validation loss decreased (0.065967 --> 0.065313).  Saving model ...\n",
      "Epoch: 62, Training Loss: 0.0486, Validation Loss: 0.0653\n",
      "Epoch: 63, Training Loss: 0.0798, Validation Loss: 0.0646\n",
      "Validation loss decreased (0.065313 --> 0.064584).  Saving model ...\n",
      "Epoch: 64, Training Loss: 0.0441, Validation Loss: 0.0634\n",
      "Validation loss decreased (0.064584 --> 0.063352).  Saving model ...\n",
      "Epoch: 65, Training Loss: 0.0454, Validation Loss: 0.0634\n",
      "Epoch: 66, Training Loss: 0.0525, Validation Loss: 0.0647\n",
      "Epoch: 67, Training Loss: 0.0454, Validation Loss: 0.0638\n",
      "Epoch: 68, Training Loss: 0.0541, Validation Loss: 0.0640\n",
      "Epoch: 69, Training Loss: 0.0441, Validation Loss: 0.0640\n",
      "Epoch: 70, Training Loss: 0.0619, Validation Loss: 0.0629\n",
      "Validation loss decreased (0.063352 --> 0.062932).  Saving model ...\n",
      "Epoch: 71, Training Loss: 0.0555, Validation Loss: 0.0623\n",
      "Validation loss decreased (0.062932 --> 0.062319).  Saving model ...\n",
      "Epoch: 72, Training Loss: 0.0472, Validation Loss: 0.0627\n",
      "Epoch: 73, Training Loss: 0.0566, Validation Loss: 0.0615\n",
      "Validation loss decreased (0.062319 --> 0.061481).  Saving model ...\n",
      "Epoch: 74, Training Loss: 0.0472, Validation Loss: 0.0618\n",
      "Epoch: 75, Training Loss: 0.0444, Validation Loss: 0.0613\n",
      "Validation loss decreased (0.061481 --> 0.061306).  Saving model ...\n",
      "Epoch: 76, Training Loss: 0.0582, Validation Loss: 0.0589\n",
      "Validation loss decreased (0.061306 --> 0.058892).  Saving model ...\n",
      "Epoch: 77, Training Loss: 0.0466, Validation Loss: 0.0596\n",
      "Epoch: 78, Training Loss: 0.0404, Validation Loss: 0.0602\n",
      "Epoch: 79, Training Loss: 0.0567, Validation Loss: 0.0597\n",
      "Epoch: 80, Training Loss: 0.0624, Validation Loss: 0.0585\n",
      "Validation loss decreased (0.058892 --> 0.058538).  Saving model ...\n",
      "Epoch: 81, Training Loss: 0.0391, Validation Loss: 0.0588\n",
      "Epoch: 82, Training Loss: 0.0461, Validation Loss: 0.0594\n",
      "Epoch: 83, Training Loss: 0.0555, Validation Loss: 0.0588\n",
      "Epoch: 84, Training Loss: 0.0455, Validation Loss: 0.0571\n",
      "Validation loss decreased (0.058538 --> 0.057118).  Saving model ...\n",
      "Epoch: 85, Training Loss: 0.0427, Validation Loss: 0.0570\n",
      "Epoch: 86, Training Loss: 0.0557, Validation Loss: 0.0573\n",
      "Epoch: 87, Training Loss: 0.0529, Validation Loss: 0.0576\n",
      "Epoch: 88, Training Loss: 0.0380, Validation Loss: 0.0566\n",
      "Validation loss decreased (0.057118 --> 0.056633).  Saving model ...\n",
      "Epoch: 89, Training Loss: 0.0431, Validation Loss: 0.0554\n",
      "Validation loss decreased (0.056633 --> 0.055387).  Saving model ...\n",
      "Epoch: 90, Training Loss: 0.0439, Validation Loss: 0.0552\n",
      "Validation loss decreased (0.055387 --> 0.055203).  Saving model ...\n",
      "Epoch: 91, Training Loss: 0.0546, Validation Loss: 0.0553\n",
      "Epoch: 92, Training Loss: 0.0523, Validation Loss: 0.0559\n",
      "Epoch: 93, Training Loss: 0.0394, Validation Loss: 0.0548\n",
      "Validation loss decreased (0.055203 --> 0.054782).  Saving model ...\n",
      "Epoch: 94, Training Loss: 0.0337, Validation Loss: 0.0541\n",
      "Validation loss decreased (0.054782 --> 0.054120).  Saving model ...\n",
      "Epoch: 95, Training Loss: 0.0516, Validation Loss: 0.0548\n",
      "Epoch: 96, Training Loss: 0.0466, Validation Loss: 0.0572\n",
      "Epoch: 97, Training Loss: 0.0591, Validation Loss: 0.0585\n",
      "Epoch: 98, Training Loss: 0.0464, Validation Loss: 0.0578\n",
      "Epoch: 99, Training Loss: 0.0465, Validation Loss: 0.0558\n",
      "Epoch: 100, Training Loss: 0.0471, Validation Loss: 0.0550\n",
      "Epoch: 101, Training Loss: 0.0493, Validation Loss: 0.0552\n",
      "Epoch: 102, Training Loss: 0.0471, Validation Loss: 0.0556\n",
      "Epoch: 103, Training Loss: 0.0645, Validation Loss: 0.0569\n",
      "Epoch: 104, Training Loss: 0.0586, Validation Loss: 0.0546\n",
      "Epoch: 105, Training Loss: 0.0455, Validation Loss: 0.0531\n",
      "Validation loss decreased (0.054120 --> 0.053096).  Saving model ...\n",
      "Epoch: 106, Training Loss: 0.0527, Validation Loss: 0.0540\n",
      "Epoch: 107, Training Loss: 0.0631, Validation Loss: 0.0541\n",
      "Epoch: 108, Training Loss: 0.0565, Validation Loss: 0.0539\n",
      "Epoch: 109, Training Loss: 0.0508, Validation Loss: 0.0542\n",
      "Epoch: 110, Training Loss: 0.0507, Validation Loss: 0.0549\n",
      "Epoch: 111, Training Loss: 0.0420, Validation Loss: 0.0534\n",
      "Epoch: 112, Training Loss: 0.0475, Validation Loss: 0.0528\n",
      "Validation loss decreased (0.053096 --> 0.052811).  Saving model ...\n",
      "Epoch: 113, Training Loss: 0.0496, Validation Loss: 0.0522\n",
      "Validation loss decreased (0.052811 --> 0.052213).  Saving model ...\n",
      "Epoch: 114, Training Loss: 0.0582, Validation Loss: 0.0529\n",
      "Epoch: 115, Training Loss: 0.0676, Validation Loss: 0.0536\n",
      "Epoch: 116, Training Loss: 0.0486, Validation Loss: 0.0530\n",
      "Epoch: 117, Training Loss: 0.0378, Validation Loss: 0.0519\n",
      "Validation loss decreased (0.052213 --> 0.051868).  Saving model ...\n",
      "Epoch: 118, Training Loss: 0.0476, Validation Loss: 0.0517\n",
      "Validation loss decreased (0.051868 --> 0.051658).  Saving model ...\n",
      "Epoch: 119, Training Loss: 0.0567, Validation Loss: 0.0529\n",
      "Epoch: 120, Training Loss: 0.0438, Validation Loss: 0.0529\n",
      "Epoch: 121, Training Loss: 0.0448, Validation Loss: 0.0520\n",
      "Epoch: 122, Training Loss: 0.0602, Validation Loss: 0.0528\n",
      "Epoch: 123, Training Loss: 0.0351, Validation Loss: 0.0532\n",
      "Epoch: 124, Training Loss: 0.0556, Validation Loss: 0.0535\n",
      "Epoch: 125, Training Loss: 0.0373, Validation Loss: 0.0517\n",
      "Epoch: 126, Training Loss: 0.0452, Validation Loss: 0.0530\n",
      "Epoch: 127, Training Loss: 0.0459, Validation Loss: 0.0541\n",
      "Epoch: 128, Training Loss: 0.0395, Validation Loss: 0.0527\n",
      "Epoch: 129, Training Loss: 0.0447, Validation Loss: 0.0507\n",
      "Validation loss decreased (0.051658 --> 0.050728).  Saving model ...\n",
      "Epoch: 130, Training Loss: 0.0493, Validation Loss: 0.0512\n",
      "Epoch: 131, Training Loss: 0.0423, Validation Loss: 0.0510\n",
      "Epoch: 132, Training Loss: 0.0492, Validation Loss: 0.0501\n",
      "Validation loss decreased (0.050728 --> 0.050133).  Saving model ...\n",
      "Epoch: 133, Training Loss: 0.0408, Validation Loss: 0.0506\n",
      "Epoch: 134, Training Loss: 0.0479, Validation Loss: 0.0495\n",
      "Validation loss decreased (0.050133 --> 0.049502).  Saving model ...\n",
      "Epoch: 135, Training Loss: 0.0430, Validation Loss: 0.0507\n",
      "Epoch: 136, Training Loss: 0.0402, Validation Loss: 0.0506\n",
      "Epoch: 137, Training Loss: 0.0383, Validation Loss: 0.0496\n",
      "Epoch: 138, Training Loss: 0.0433, Validation Loss: 0.0500\n",
      "Epoch: 139, Training Loss: 0.0501, Validation Loss: 0.0517\n",
      "Epoch: 140, Training Loss: 0.0442, Validation Loss: 0.0513\n",
      "Epoch: 141, Training Loss: 0.0559, Validation Loss: 0.0535\n",
      "Epoch: 142, Training Loss: 0.0403, Validation Loss: 0.0520\n",
      "Epoch: 143, Training Loss: 0.0454, Validation Loss: 0.0506\n",
      "Epoch: 144, Training Loss: 0.0473, Validation Loss: 0.0488\n",
      "Validation loss decreased (0.049502 --> 0.048841).  Saving model ...\n",
      "Epoch: 145, Training Loss: 0.0492, Validation Loss: 0.0510\n",
      "Epoch: 146, Training Loss: 0.0358, Validation Loss: 0.0510\n",
      "Epoch: 147, Training Loss: 0.0440, Validation Loss: 0.0496\n",
      "Epoch: 148, Training Loss: 0.0374, Validation Loss: 0.0488\n",
      "Epoch: 149, Training Loss: 0.0371, Validation Loss: 0.0493\n",
      "Epoch: 150, Training Loss: 0.0651, Validation Loss: 0.0492\n",
      "Epoch: 151, Training Loss: 0.0351, Validation Loss: 0.0484\n",
      "Validation loss decreased (0.048841 --> 0.048403).  Saving model ...\n",
      "Epoch: 152, Training Loss: 0.0481, Validation Loss: 0.0481\n",
      "Validation loss decreased (0.048403 --> 0.048089).  Saving model ...\n",
      "Epoch: 153, Training Loss: 0.0489, Validation Loss: 0.0485\n",
      "Epoch: 154, Training Loss: 0.0404, Validation Loss: 0.0486\n",
      "Epoch: 155, Training Loss: 0.0424, Validation Loss: 0.0491\n",
      "Epoch: 156, Training Loss: 0.0425, Validation Loss: 0.0487\n",
      "Epoch: 157, Training Loss: 0.0433, Validation Loss: 0.0501\n",
      "Epoch: 158, Training Loss: 0.0508, Validation Loss: 0.0485\n",
      "Epoch: 159, Training Loss: 0.0365, Validation Loss: 0.0492\n",
      "Epoch: 160, Training Loss: 0.0489, Validation Loss: 0.0488\n",
      "Epoch: 161, Training Loss: 0.0394, Validation Loss: 0.0468\n",
      "Validation loss decreased (0.048089 --> 0.046795).  Saving model ...\n",
      "Epoch: 162, Training Loss: 0.0474, Validation Loss: 0.0478\n",
      "Epoch: 163, Training Loss: 0.0438, Validation Loss: 0.0487\n",
      "Epoch: 164, Training Loss: 0.0366, Validation Loss: 0.0464\n",
      "Validation loss decreased (0.046795 --> 0.046368).  Saving model ...\n",
      "Epoch: 165, Training Loss: 0.0387, Validation Loss: 0.0482\n",
      "Epoch: 166, Training Loss: 0.0520, Validation Loss: 0.0492\n",
      "Epoch: 167, Training Loss: 0.0437, Validation Loss: 0.0467\n",
      "Epoch: 168, Training Loss: 0.0387, Validation Loss: 0.0468\n",
      "Epoch: 169, Training Loss: 0.0493, Validation Loss: 0.0476\n",
      "Epoch: 170, Training Loss: 0.0536, Validation Loss: 0.0483\n",
      "Epoch: 171, Training Loss: 0.0420, Validation Loss: 0.0470\n",
      "Epoch: 172, Training Loss: 0.0393, Validation Loss: 0.0477\n",
      "Epoch: 173, Training Loss: 0.0475, Validation Loss: 0.0467\n",
      "Epoch: 174, Training Loss: 0.0431, Validation Loss: 0.0459\n",
      "Validation loss decreased (0.046368 --> 0.045945).  Saving model ...\n",
      "Epoch: 175, Training Loss: 0.0386, Validation Loss: 0.0455\n",
      "Validation loss decreased (0.045945 --> 0.045467).  Saving model ...\n",
      "Epoch: 176, Training Loss: 0.0415, Validation Loss: 0.0457\n",
      "Epoch: 177, Training Loss: 0.0343, Validation Loss: 0.0467\n",
      "Epoch: 178, Training Loss: 0.0427, Validation Loss: 0.0474\n",
      "Epoch: 179, Training Loss: 0.0469, Validation Loss: 0.0480\n",
      "Epoch: 180, Training Loss: 0.0474, Validation Loss: 0.0469\n",
      "Epoch: 181, Training Loss: 0.0454, Validation Loss: 0.0472\n",
      "Epoch: 182, Training Loss: 0.0406, Validation Loss: 0.0463\n",
      "Epoch: 183, Training Loss: 0.0448, Validation Loss: 0.0454\n",
      "Epoch: 184, Training Loss: 0.0435, Validation Loss: 0.0451\n",
      "Validation loss decreased (0.045467 --> 0.045095).  Saving model ...\n",
      "Epoch: 185, Training Loss: 0.0429, Validation Loss: 0.0461\n",
      "Epoch: 186, Training Loss: 0.0360, Validation Loss: 0.0474\n",
      "Epoch: 187, Training Loss: 0.0427, Validation Loss: 0.0468\n",
      "Epoch: 188, Training Loss: 0.0401, Validation Loss: 0.0475\n",
      "Epoch: 189, Training Loss: 0.0427, Validation Loss: 0.0470\n",
      "Epoch: 190, Training Loss: 0.0416, Validation Loss: 0.0461\n",
      "Epoch: 191, Training Loss: 0.0398, Validation Loss: 0.0456\n",
      "Epoch: 192, Training Loss: 0.0543, Validation Loss: 0.0470\n",
      "Epoch: 193, Training Loss: 0.0389, Validation Loss: 0.0472\n",
      "Epoch: 194, Training Loss: 0.0453, Validation Loss: 0.0474\n",
      "Epoch: 195, Training Loss: 0.0404, Validation Loss: 0.0450\n",
      "Epoch: 196, Training Loss: 0.0404, Validation Loss: 0.0460\n",
      "Epoch: 197, Training Loss: 0.0458, Validation Loss: 0.0443\n",
      "Validation loss decreased (0.045095 --> 0.044347).  Saving model ...\n",
      "Epoch: 198, Training Loss: 0.0418, Validation Loss: 0.0458\n",
      "Epoch: 199, Training Loss: 0.0344, Validation Loss: 0.0459\n",
      "Epoch: 200, Training Loss: 0.0384, Validation Loss: 0.0457\n",
      "Epoch: 201, Training Loss: 0.0355, Validation Loss: 0.0443\n",
      "Epoch: 202, Training Loss: 0.0409, Validation Loss: 0.0433\n",
      "Validation loss decreased (0.044347 --> 0.043304).  Saving model ...\n",
      "Epoch: 203, Training Loss: 0.0386, Validation Loss: 0.0439\n",
      "Epoch: 204, Training Loss: 0.0397, Validation Loss: 0.0462\n",
      "Epoch: 205, Training Loss: 0.0373, Validation Loss: 0.0458\n",
      "Epoch: 206, Training Loss: 0.0454, Validation Loss: 0.0443\n",
      "Epoch: 207, Training Loss: 0.0402, Validation Loss: 0.0437\n",
      "Epoch: 208, Training Loss: 0.0541, Validation Loss: 0.0448\n",
      "Epoch: 209, Training Loss: 0.0403, Validation Loss: 0.0444\n",
      "Epoch: 210, Training Loss: 0.0318, Validation Loss: 0.0444\n",
      "Epoch: 211, Training Loss: 0.0361, Validation Loss: 0.0437\n",
      "Epoch: 212, Training Loss: 0.0363, Validation Loss: 0.0442\n",
      "Epoch: 213, Training Loss: 0.0389, Validation Loss: 0.0424\n",
      "Validation loss decreased (0.043304 --> 0.042392).  Saving model ...\n",
      "Epoch: 214, Training Loss: 0.0361, Validation Loss: 0.0436\n",
      "Epoch: 215, Training Loss: 0.0360, Validation Loss: 0.0444\n",
      "Epoch: 216, Training Loss: 0.0384, Validation Loss: 0.0441\n",
      "Epoch: 217, Training Loss: 0.0425, Validation Loss: 0.0434\n",
      "Epoch: 218, Training Loss: 0.0417, Validation Loss: 0.0447\n",
      "Epoch: 219, Training Loss: 0.0377, Validation Loss: 0.0447\n",
      "Epoch: 220, Training Loss: 0.0433, Validation Loss: 0.0441\n",
      "Epoch: 221, Training Loss: 0.0411, Validation Loss: 0.0452\n",
      "Epoch: 222, Training Loss: 0.0535, Validation Loss: 0.0461\n",
      "Epoch: 223, Training Loss: 0.0403, Validation Loss: 0.0438\n",
      "Epoch: 224, Training Loss: 0.0445, Validation Loss: 0.0429\n",
      "Epoch: 225, Training Loss: 0.0390, Validation Loss: 0.0435\n",
      "Epoch: 226, Training Loss: 0.0352, Validation Loss: 0.0426\n",
      "Epoch: 227, Training Loss: 0.0537, Validation Loss: 0.0440\n",
      "Epoch: 228, Training Loss: 0.0378, Validation Loss: 0.0439\n",
      "Epoch: 229, Training Loss: 0.0435, Validation Loss: 0.0437\n",
      "Epoch: 230, Training Loss: 0.0498, Validation Loss: 0.0438\n",
      "Epoch: 231, Training Loss: 0.0335, Validation Loss: 0.0431\n",
      "Epoch: 232, Training Loss: 0.0447, Validation Loss: 0.0434\n",
      "Epoch: 233, Training Loss: 0.0471, Validation Loss: 0.0435\n",
      "Epoch: 234, Training Loss: 0.0372, Validation Loss: 0.0418\n",
      "Validation loss decreased (0.042392 --> 0.041761).  Saving model ...\n",
      "Epoch: 235, Training Loss: 0.0398, Validation Loss: 0.0424\n",
      "Epoch: 236, Training Loss: 0.0404, Validation Loss: 0.0431\n",
      "Epoch: 237, Training Loss: 0.0318, Validation Loss: 0.0411\n",
      "Validation loss decreased (0.041761 --> 0.041105).  Saving model ...\n",
      "Epoch: 238, Training Loss: 0.0412, Validation Loss: 0.0431\n",
      "Epoch: 239, Training Loss: 0.0304, Validation Loss: 0.0436\n",
      "Epoch: 240, Training Loss: 0.0393, Validation Loss: 0.0437\n",
      "Epoch: 241, Training Loss: 0.0389, Validation Loss: 0.0426\n",
      "Epoch: 242, Training Loss: 0.0367, Validation Loss: 0.0422\n",
      "Epoch: 243, Training Loss: 0.0351, Validation Loss: 0.0429\n",
      "Epoch: 244, Training Loss: 0.0378, Validation Loss: 0.0429\n",
      "Epoch: 245, Training Loss: 0.0385, Validation Loss: 0.0422\n",
      "Epoch: 246, Training Loss: 0.0441, Validation Loss: 0.0435\n",
      "Epoch: 247, Training Loss: 0.0432, Validation Loss: 0.0433\n",
      "Epoch: 248, Training Loss: 0.0363, Validation Loss: 0.0424\n",
      "Epoch: 249, Training Loss: 0.0364, Validation Loss: 0.0410\n",
      "Validation loss decreased (0.041105 --> 0.041004).  Saving model ...\n",
      "Epoch: 250, Training Loss: 0.0320, Validation Loss: 0.0428\n",
      "Epoch: 251, Training Loss: 0.0349, Validation Loss: 0.0419\n",
      "Epoch: 252, Training Loss: 0.0500, Validation Loss: 0.0414\n",
      "Epoch: 253, Training Loss: 0.0357, Validation Loss: 0.0425\n",
      "Epoch: 254, Training Loss: 0.0356, Validation Loss: 0.0420\n",
      "Epoch: 255, Training Loss: 0.0362, Validation Loss: 0.0415\n",
      "Epoch: 256, Training Loss: 0.0403, Validation Loss: 0.0419\n",
      "Epoch: 257, Training Loss: 0.0433, Validation Loss: 0.0433\n",
      "Epoch: 258, Training Loss: 0.0508, Validation Loss: 0.0421\n",
      "Epoch: 259, Training Loss: 0.0365, Validation Loss: 0.0408\n",
      "Validation loss decreased (0.041004 --> 0.040840).  Saving model ...\n",
      "Epoch: 260, Training Loss: 0.0351, Validation Loss: 0.0431\n",
      "Epoch: 261, Training Loss: 0.0338, Validation Loss: 0.0439\n",
      "Epoch: 262, Training Loss: 0.0445, Validation Loss: 0.0416\n",
      "Epoch: 263, Training Loss: 0.0354, Validation Loss: 0.0424\n",
      "Epoch: 264, Training Loss: 0.0395, Validation Loss: 0.0423\n",
      "Epoch: 265, Training Loss: 0.0348, Validation Loss: 0.0412\n",
      "Epoch: 266, Training Loss: 0.0295, Validation Loss: 0.0424\n",
      "Epoch: 267, Training Loss: 0.0300, Validation Loss: 0.0414\n",
      "Epoch: 268, Training Loss: 0.0371, Validation Loss: 0.0405\n",
      "Validation loss decreased (0.040840 --> 0.040537).  Saving model ...\n",
      "Epoch: 269, Training Loss: 0.0374, Validation Loss: 0.0410\n",
      "Epoch: 270, Training Loss: 0.0359, Validation Loss: 0.0418\n",
      "Epoch: 271, Training Loss: 0.0392, Validation Loss: 0.0422\n",
      "Epoch: 272, Training Loss: 0.0426, Validation Loss: 0.0407\n",
      "Epoch: 273, Training Loss: 0.0346, Validation Loss: 0.0421\n",
      "Epoch: 274, Training Loss: 0.0368, Validation Loss: 0.0437\n",
      "Epoch: 275, Training Loss: 0.0407, Validation Loss: 0.0415\n",
      "Epoch: 276, Training Loss: 0.0385, Validation Loss: 0.0424\n",
      "Epoch: 277, Training Loss: 0.0421, Validation Loss: 0.0415\n",
      "Epoch: 278, Training Loss: 0.0342, Validation Loss: 0.0422\n",
      "Epoch: 279, Training Loss: 0.0400, Validation Loss: 0.0420\n",
      "Epoch: 280, Training Loss: 0.0401, Validation Loss: 0.0414\n",
      "Epoch: 281, Training Loss: 0.0429, Validation Loss: 0.0414\n",
      "Epoch: 282, Training Loss: 0.0347, Validation Loss: 0.0412\n",
      "Epoch: 283, Training Loss: 0.0447, Validation Loss: 0.0408\n",
      "Epoch: 284, Training Loss: 0.0380, Validation Loss: 0.0406\n",
      "Epoch: 285, Training Loss: 0.0331, Validation Loss: 0.0406\n",
      "Epoch: 286, Training Loss: 0.0313, Validation Loss: 0.0406\n",
      "Epoch: 287, Training Loss: 0.0386, Validation Loss: 0.0401\n",
      "Validation loss decreased (0.040537 --> 0.040087).  Saving model ...\n",
      "Epoch: 288, Training Loss: 0.0512, Validation Loss: 0.0410\n",
      "Epoch: 289, Training Loss: 0.0400, Validation Loss: 0.0420\n",
      "Epoch: 290, Training Loss: 0.0319, Validation Loss: 0.0419\n",
      "Epoch: 291, Training Loss: 0.0336, Validation Loss: 0.0418\n",
      "Epoch: 292, Training Loss: 0.0399, Validation Loss: 0.0426\n",
      "Epoch: 293, Training Loss: 0.0326, Validation Loss: 0.0421\n",
      "Epoch: 294, Training Loss: 0.0327, Validation Loss: 0.0404\n",
      "Epoch: 295, Training Loss: 0.0491, Validation Loss: 0.0408\n",
      "Epoch: 296, Training Loss: 0.0345, Validation Loss: 0.0414\n",
      "Epoch: 297, Training Loss: 0.0368, Validation Loss: 0.0417\n",
      "Epoch: 298, Training Loss: 0.0329, Validation Loss: 0.0404\n",
      "Epoch: 299, Training Loss: 0.0344, Validation Loss: 0.0408\n",
      "Epoch: 300, Training Loss: 0.0309, Validation Loss: 0.0412\n",
      "Epoch: 301, Training Loss: 0.0348, Validation Loss: 0.0410\n",
      "Epoch: 302, Training Loss: 0.0384, Validation Loss: 0.0410\n",
      "Epoch: 303, Training Loss: 0.0371, Validation Loss: 0.0404\n",
      "Epoch: 304, Training Loss: 0.0386, Validation Loss: 0.0396\n",
      "Validation loss decreased (0.040087 --> 0.039569).  Saving model ...\n",
      "Epoch: 305, Training Loss: 0.0307, Validation Loss: 0.0395\n",
      "Validation loss decreased (0.039569 --> 0.039466).  Saving model ...\n",
      "Epoch: 306, Training Loss: 0.0409, Validation Loss: 0.0400\n",
      "Epoch: 307, Training Loss: 0.0362, Validation Loss: 0.0400\n",
      "Epoch: 308, Training Loss: 0.0342, Validation Loss: 0.0403\n",
      "Epoch: 309, Training Loss: 0.0382, Validation Loss: 0.0406\n",
      "Epoch: 310, Training Loss: 0.0310, Validation Loss: 0.0402\n",
      "Epoch: 311, Training Loss: 0.0358, Validation Loss: 0.0399\n",
      "Epoch: 312, Training Loss: 0.0401, Validation Loss: 0.0407\n",
      "Epoch: 313, Training Loss: 0.0336, Validation Loss: 0.0397\n",
      "Epoch: 314, Training Loss: 0.0372, Validation Loss: 0.0399\n",
      "Epoch: 315, Training Loss: 0.0386, Validation Loss: 0.0408\n",
      "Epoch: 316, Training Loss: 0.0484, Validation Loss: 0.0402\n",
      "Epoch: 317, Training Loss: 0.0346, Validation Loss: 0.0403\n",
      "Epoch: 318, Training Loss: 0.0334, Validation Loss: 0.0401\n",
      "Epoch: 319, Training Loss: 0.0378, Validation Loss: 0.0398\n",
      "Epoch: 320, Training Loss: 0.0321, Validation Loss: 0.0397\n",
      "Epoch: 321, Training Loss: 0.0425, Validation Loss: 0.0408\n",
      "Epoch: 322, Training Loss: 0.0296, Validation Loss: 0.0398\n",
      "Epoch: 323, Training Loss: 0.0285, Validation Loss: 0.0395\n",
      "Epoch: 324, Training Loss: 0.0363, Validation Loss: 0.0399\n",
      "Epoch: 325, Training Loss: 0.0295, Validation Loss: 0.0399\n",
      "Epoch: 326, Training Loss: 0.0297, Validation Loss: 0.0406\n",
      "Epoch: 327, Training Loss: 0.0381, Validation Loss: 0.0397\n",
      "Epoch: 328, Training Loss: 0.0319, Validation Loss: 0.0395\n",
      "Epoch: 329, Training Loss: 0.0362, Validation Loss: 0.0406\n",
      "Epoch: 330, Training Loss: 0.0404, Validation Loss: 0.0412\n",
      "Epoch: 331, Training Loss: 0.0451, Validation Loss: 0.0388\n",
      "Validation loss decreased (0.039466 --> 0.038792).  Saving model ...\n",
      "Epoch: 332, Training Loss: 0.0435, Validation Loss: 0.0399\n",
      "Epoch: 333, Training Loss: 0.0380, Validation Loss: 0.0405\n",
      "Epoch: 334, Training Loss: 0.0357, Validation Loss: 0.0395\n",
      "Epoch: 335, Training Loss: 0.0302, Validation Loss: 0.0390\n",
      "Epoch: 336, Training Loss: 0.0424, Validation Loss: 0.0385\n",
      "Validation loss decreased (0.038792 --> 0.038532).  Saving model ...\n",
      "Epoch: 337, Training Loss: 0.0331, Validation Loss: 0.0407\n",
      "Epoch: 338, Training Loss: 0.0328, Validation Loss: 0.0415\n",
      "Epoch: 339, Training Loss: 0.0308, Validation Loss: 0.0390\n",
      "Epoch: 340, Training Loss: 0.0359, Validation Loss: 0.0399\n",
      "Epoch: 341, Training Loss: 0.0387, Validation Loss: 0.0392\n",
      "Epoch: 342, Training Loss: 0.0511, Validation Loss: 0.0402\n",
      "Epoch: 343, Training Loss: 0.0402, Validation Loss: 0.0399\n",
      "Epoch: 344, Training Loss: 0.0284, Validation Loss: 0.0398\n",
      "Epoch: 345, Training Loss: 0.0387, Validation Loss: 0.0397\n",
      "Epoch: 346, Training Loss: 0.0360, Validation Loss: 0.0391\n",
      "Epoch: 347, Training Loss: 0.0262, Validation Loss: 0.0394\n",
      "Epoch: 348, Training Loss: 0.0334, Validation Loss: 0.0391\n",
      "Epoch: 349, Training Loss: 0.0314, Validation Loss: 0.0403\n",
      "Epoch: 350, Training Loss: 0.0334, Validation Loss: 0.0397\n",
      "Epoch: 351, Training Loss: 0.0371, Validation Loss: 0.0391\n",
      "Epoch: 352, Training Loss: 0.0310, Validation Loss: 0.0404\n",
      "Epoch: 353, Training Loss: 0.0441, Validation Loss: 0.0397\n",
      "Epoch: 354, Training Loss: 0.0331, Validation Loss: 0.0388\n",
      "Epoch: 355, Training Loss: 0.0284, Validation Loss: 0.0390\n",
      "Epoch: 356, Training Loss: 0.0354, Validation Loss: 0.0393\n",
      "Epoch: 357, Training Loss: 0.0393, Validation Loss: 0.0385\n",
      "Epoch: 358, Training Loss: 0.0382, Validation Loss: 0.0397\n",
      "Epoch: 359, Training Loss: 0.0422, Validation Loss: 0.0402\n",
      "Epoch: 360, Training Loss: 0.0250, Validation Loss: 0.0382\n",
      "Validation loss decreased (0.038532 --> 0.038165).  Saving model ...\n",
      "Epoch: 361, Training Loss: 0.0333, Validation Loss: 0.0392\n",
      "Epoch: 362, Training Loss: 0.0327, Validation Loss: 0.0397\n",
      "Epoch: 363, Training Loss: 0.0335, Validation Loss: 0.0392\n",
      "Epoch: 364, Training Loss: 0.0280, Validation Loss: 0.0395\n",
      "Epoch: 365, Training Loss: 0.0367, Validation Loss: 0.0386\n",
      "Epoch: 366, Training Loss: 0.0569, Validation Loss: 0.0384\n",
      "Epoch: 367, Training Loss: 0.0445, Validation Loss: 0.0388\n",
      "Epoch: 368, Training Loss: 0.0316, Validation Loss: 0.0395\n",
      "Epoch: 369, Training Loss: 0.0339, Validation Loss: 0.0387\n",
      "Epoch: 370, Training Loss: 0.0265, Validation Loss: 0.0388\n",
      "Epoch: 371, Training Loss: 0.0372, Validation Loss: 0.0392\n",
      "Epoch: 372, Training Loss: 0.0322, Validation Loss: 0.0394\n",
      "Epoch: 373, Training Loss: 0.0455, Validation Loss: 0.0380\n",
      "Validation loss decreased (0.038165 --> 0.038020).  Saving model ...\n",
      "Epoch: 374, Training Loss: 0.0316, Validation Loss: 0.0381\n",
      "Epoch: 375, Training Loss: 0.0338, Validation Loss: 0.0387\n",
      "Epoch: 376, Training Loss: 0.0316, Validation Loss: 0.0407\n",
      "Epoch: 377, Training Loss: 0.0339, Validation Loss: 0.0392\n",
      "Epoch: 378, Training Loss: 0.0330, Validation Loss: 0.0385\n",
      "Epoch: 379, Training Loss: 0.0256, Validation Loss: 0.0403\n",
      "Epoch: 380, Training Loss: 0.0344, Validation Loss: 0.0395\n",
      "Epoch: 381, Training Loss: 0.0328, Validation Loss: 0.0380\n",
      "Epoch: 382, Training Loss: 0.0346, Validation Loss: 0.0378\n",
      "Validation loss decreased (0.038020 --> 0.037815).  Saving model ...\n",
      "Epoch: 383, Training Loss: 0.0396, Validation Loss: 0.0389\n",
      "Epoch: 384, Training Loss: 0.0351, Validation Loss: 0.0385\n",
      "Epoch: 385, Training Loss: 0.0443, Validation Loss: 0.0387\n",
      "Epoch: 386, Training Loss: 0.0319, Validation Loss: 0.0374\n",
      "Validation loss decreased (0.037815 --> 0.037401).  Saving model ...\n",
      "Epoch: 387, Training Loss: 0.0626, Validation Loss: 0.0380\n",
      "Epoch: 388, Training Loss: 0.0348, Validation Loss: 0.0376\n",
      "Epoch: 389, Training Loss: 0.0347, Validation Loss: 0.0378\n",
      "Epoch: 390, Training Loss: 0.0353, Validation Loss: 0.0376\n",
      "Epoch: 391, Training Loss: 0.0322, Validation Loss: 0.0373\n",
      "Epoch: 392, Training Loss: 0.0404, Validation Loss: 0.0382\n",
      "Epoch: 393, Training Loss: 0.0376, Validation Loss: 0.0385\n",
      "Epoch: 394, Training Loss: 0.0418, Validation Loss: 0.0403\n",
      "Epoch: 395, Training Loss: 0.0320, Validation Loss: 0.0394\n",
      "Epoch: 396, Training Loss: 0.0322, Validation Loss: 0.0386\n",
      "Epoch: 397, Training Loss: 0.0420, Validation Loss: 0.0375\n",
      "Epoch: 398, Training Loss: 0.0349, Validation Loss: 0.0383\n",
      "Epoch: 399, Training Loss: 0.0366, Validation Loss: 0.0376\n",
      "Epoch: 400, Training Loss: 0.0403, Validation Loss: 0.0375\n",
      "Epoch: 401, Training Loss: 0.0317, Validation Loss: 0.0383\n",
      "Epoch: 402, Training Loss: 0.0373, Validation Loss: 0.0380\n",
      "Epoch: 403, Training Loss: 0.0359, Validation Loss: 0.0385\n",
      "Epoch: 404, Training Loss: 0.0332, Validation Loss: 0.0388\n",
      "Epoch: 405, Training Loss: 0.0401, Validation Loss: 0.0377\n",
      "Epoch: 406, Training Loss: 0.0396, Validation Loss: 0.0370\n",
      "Validation loss decreased (0.037401 --> 0.036996).  Saving model ...\n",
      "Epoch: 407, Training Loss: 0.0274, Validation Loss: 0.0393\n",
      "Epoch: 408, Training Loss: 0.0359, Validation Loss: 0.0385\n",
      "Epoch: 409, Training Loss: 0.0325, Validation Loss: 0.0368\n",
      "Validation loss decreased (0.036996 --> 0.036831).  Saving model ...\n",
      "Epoch: 410, Training Loss: 0.0434, Validation Loss: 0.0381\n",
      "Epoch: 411, Training Loss: 0.0288, Validation Loss: 0.0389\n",
      "Epoch: 412, Training Loss: 0.0404, Validation Loss: 0.0383\n",
      "Epoch: 413, Training Loss: 0.0327, Validation Loss: 0.0375\n",
      "Epoch: 414, Training Loss: 0.0373, Validation Loss: 0.0368\n",
      "Epoch: 415, Training Loss: 0.0341, Validation Loss: 0.0368\n",
      "Epoch: 416, Training Loss: 0.0359, Validation Loss: 0.0378\n",
      "Epoch: 417, Training Loss: 0.0481, Validation Loss: 0.0391\n",
      "Epoch: 418, Training Loss: 0.0445, Validation Loss: 0.0381\n",
      "Epoch: 419, Training Loss: 0.0308, Validation Loss: 0.0375\n",
      "Epoch: 420, Training Loss: 0.0357, Validation Loss: 0.0380\n",
      "Epoch: 421, Training Loss: 0.0345, Validation Loss: 0.0372\n",
      "Epoch: 422, Training Loss: 0.0288, Validation Loss: 0.0387\n",
      "Epoch: 423, Training Loss: 0.0349, Validation Loss: 0.0380\n",
      "Epoch: 424, Training Loss: 0.0423, Validation Loss: 0.0380\n",
      "Epoch: 425, Training Loss: 0.0376, Validation Loss: 0.0368\n",
      "Epoch: 426, Training Loss: 0.0418, Validation Loss: 0.0369\n",
      "Epoch: 427, Training Loss: 0.0373, Validation Loss: 0.0384\n",
      "Epoch: 428, Training Loss: 0.0539, Validation Loss: 0.0376\n",
      "Epoch: 429, Training Loss: 0.0304, Validation Loss: 0.0368\n",
      "Epoch: 430, Training Loss: 0.0408, Validation Loss: 0.0371\n",
      "Epoch: 431, Training Loss: 0.0405, Validation Loss: 0.0375\n",
      "Epoch: 432, Training Loss: 0.0400, Validation Loss: 0.0367\n",
      "Epoch: 433, Training Loss: 0.0423, Validation Loss: 0.0377\n",
      "Epoch: 434, Training Loss: 0.0379, Validation Loss: 0.0384\n",
      "Epoch: 435, Training Loss: 0.0395, Validation Loss: 0.0378\n",
      "Epoch: 436, Training Loss: 0.0369, Validation Loss: 0.0365\n",
      "Validation loss decreased (0.036831 --> 0.036494).  Saving model ...\n",
      "Epoch: 437, Training Loss: 0.0394, Validation Loss: 0.0379\n",
      "Epoch: 438, Training Loss: 0.0351, Validation Loss: 0.0372\n",
      "Epoch: 439, Training Loss: 0.0308, Validation Loss: 0.0386\n",
      "Epoch: 440, Training Loss: 0.0296, Validation Loss: 0.0376\n",
      "Epoch: 441, Training Loss: 0.0345, Validation Loss: 0.0376\n",
      "Epoch: 442, Training Loss: 0.0314, Validation Loss: 0.0373\n",
      "Epoch: 443, Training Loss: 0.0347, Validation Loss: 0.0364\n",
      "Validation loss decreased (0.036494 --> 0.036363).  Saving model ...\n",
      "Epoch: 444, Training Loss: 0.0321, Validation Loss: 0.0371\n",
      "Epoch: 445, Training Loss: 0.0414, Validation Loss: 0.0379\n",
      "Epoch: 446, Training Loss: 0.0296, Validation Loss: 0.0380\n",
      "Epoch: 447, Training Loss: 0.0298, Validation Loss: 0.0375\n",
      "Epoch: 448, Training Loss: 0.0336, Validation Loss: 0.0363\n",
      "Validation loss decreased (0.036363 --> 0.036254).  Saving model ...\n",
      "Epoch: 449, Training Loss: 0.0396, Validation Loss: 0.0366\n",
      "Epoch: 450, Training Loss: 0.0271, Validation Loss: 0.0367\n",
      "Epoch: 451, Training Loss: 0.0307, Validation Loss: 0.0364\n",
      "Epoch: 452, Training Loss: 0.0317, Validation Loss: 0.0380\n",
      "Epoch: 453, Training Loss: 0.0295, Validation Loss: 0.0371\n",
      "Epoch: 454, Training Loss: 0.0290, Validation Loss: 0.0364\n",
      "Epoch: 455, Training Loss: 0.0409, Validation Loss: 0.0360\n",
      "Validation loss decreased (0.036254 --> 0.036013).  Saving model ...\n",
      "Epoch: 456, Training Loss: 0.0295, Validation Loss: 0.0365\n",
      "Epoch: 457, Training Loss: 0.0302, Validation Loss: 0.0369\n",
      "Epoch: 458, Training Loss: 0.0354, Validation Loss: 0.0369\n",
      "Epoch: 459, Training Loss: 0.0333, Validation Loss: 0.0360\n",
      "Epoch: 460, Training Loss: 0.0401, Validation Loss: 0.0362\n",
      "Epoch: 461, Training Loss: 0.0253, Validation Loss: 0.0369\n",
      "Epoch: 462, Training Loss: 0.0410, Validation Loss: 0.0365\n",
      "Epoch: 463, Training Loss: 0.0294, Validation Loss: 0.0376\n",
      "Epoch: 464, Training Loss: 0.0305, Validation Loss: 0.0358\n",
      "Validation loss decreased (0.036013 --> 0.035788).  Saving model ...\n",
      "Epoch: 465, Training Loss: 0.0388, Validation Loss: 0.0352\n",
      "Validation loss decreased (0.035788 --> 0.035214).  Saving model ...\n",
      "Epoch: 466, Training Loss: 0.0411, Validation Loss: 0.0369\n",
      "Epoch: 467, Training Loss: 0.0298, Validation Loss: 0.0364\n",
      "Epoch: 468, Training Loss: 0.0375, Validation Loss: 0.0366\n",
      "Epoch: 469, Training Loss: 0.0329, Validation Loss: 0.0371\n",
      "Epoch: 470, Training Loss: 0.0365, Validation Loss: 0.0356\n",
      "Epoch: 471, Training Loss: 0.0297, Validation Loss: 0.0366\n",
      "Epoch: 472, Training Loss: 0.0395, Validation Loss: 0.0360\n",
      "Epoch: 473, Training Loss: 0.0433, Validation Loss: 0.0370\n",
      "Epoch: 474, Training Loss: 0.0308, Validation Loss: 0.0366\n",
      "Epoch: 475, Training Loss: 0.0369, Validation Loss: 0.0358\n",
      "Epoch: 476, Training Loss: 0.0335, Validation Loss: 0.0369\n",
      "Epoch: 477, Training Loss: 0.0376, Validation Loss: 0.0378\n",
      "Epoch: 478, Training Loss: 0.0297, Validation Loss: 0.0367\n",
      "Epoch: 479, Training Loss: 0.0414, Validation Loss: 0.0352\n",
      "Epoch: 480, Training Loss: 0.0423, Validation Loss: 0.0371\n",
      "Epoch: 481, Training Loss: 0.0341, Validation Loss: 0.0370\n",
      "Epoch: 482, Training Loss: 0.0354, Validation Loss: 0.0360\n",
      "Epoch: 483, Training Loss: 0.0271, Validation Loss: 0.0360\n",
      "Epoch: 484, Training Loss: 0.0331, Validation Loss: 0.0358\n",
      "Epoch: 485, Training Loss: 0.0409, Validation Loss: 0.0374\n",
      "Epoch: 486, Training Loss: 0.0366, Validation Loss: 0.0363\n",
      "Epoch: 487, Training Loss: 0.0350, Validation Loss: 0.0361\n",
      "Epoch: 488, Training Loss: 0.0368, Validation Loss: 0.0355\n",
      "Epoch: 489, Training Loss: 0.0321, Validation Loss: 0.0359\n",
      "Epoch: 490, Training Loss: 0.0376, Validation Loss: 0.0367\n",
      "Epoch: 491, Training Loss: 0.0349, Validation Loss: 0.0360\n",
      "Epoch: 492, Training Loss: 0.0301, Validation Loss: 0.0365\n",
      "Epoch: 493, Training Loss: 0.0447, Validation Loss: 0.0362\n",
      "Epoch: 494, Training Loss: 0.0313, Validation Loss: 0.0363\n",
      "Epoch: 495, Training Loss: 0.0292, Validation Loss: 0.0362\n",
      "Epoch: 496, Training Loss: 0.0501, Validation Loss: 0.0361\n",
      "Epoch: 497, Training Loss: 0.0304, Validation Loss: 0.0362\n",
      "Epoch: 498, Training Loss: 0.0301, Validation Loss: 0.0358\n",
      "Epoch: 499, Training Loss: 0.0303, Validation Loss: 0.0356\n",
      "Epoch: 500, Training Loss: 0.0397, Validation Loss: 0.0362\n",
      "Epoch: 501, Training Loss: 0.0290, Validation Loss: 0.0363\n",
      "Epoch: 502, Training Loss: 0.0223, Validation Loss: 0.0362\n",
      "Epoch: 503, Training Loss: 0.0300, Validation Loss: 0.0353\n",
      "Epoch: 504, Training Loss: 0.0281, Validation Loss: 0.0356\n",
      "Epoch: 505, Training Loss: 0.0332, Validation Loss: 0.0367\n",
      "Epoch: 506, Training Loss: 0.0304, Validation Loss: 0.0365\n",
      "Epoch: 507, Training Loss: 0.0329, Validation Loss: 0.0363\n",
      "Epoch: 508, Training Loss: 0.0363, Validation Loss: 0.0355\n",
      "Epoch: 509, Training Loss: 0.0344, Validation Loss: 0.0361\n",
      "Epoch: 510, Training Loss: 0.0379, Validation Loss: 0.0350\n",
      "Validation loss decreased (0.035214 --> 0.034957).  Saving model ...\n",
      "Epoch: 511, Training Loss: 0.0350, Validation Loss: 0.0365\n",
      "Epoch: 512, Training Loss: 0.0337, Validation Loss: 0.0364\n",
      "Epoch: 513, Training Loss: 0.0330, Validation Loss: 0.0356\n",
      "Epoch: 514, Training Loss: 0.0361, Validation Loss: 0.0353\n",
      "Epoch: 515, Training Loss: 0.0335, Validation Loss: 0.0358\n",
      "Epoch: 516, Training Loss: 0.0353, Validation Loss: 0.0354\n",
      "Epoch: 517, Training Loss: 0.0398, Validation Loss: 0.0351\n",
      "Epoch: 518, Training Loss: 0.0383, Validation Loss: 0.0344\n",
      "Validation loss decreased (0.034957 --> 0.034435).  Saving model ...\n",
      "Epoch: 519, Training Loss: 0.0360, Validation Loss: 0.0365\n",
      "Epoch: 520, Training Loss: 0.0334, Validation Loss: 0.0366\n",
      "Epoch: 521, Training Loss: 0.0360, Validation Loss: 0.0356\n",
      "Epoch: 522, Training Loss: 0.0345, Validation Loss: 0.0359\n",
      "Epoch: 523, Training Loss: 0.0335, Validation Loss: 0.0363\n",
      "Epoch: 524, Training Loss: 0.0413, Validation Loss: 0.0355\n",
      "Epoch: 525, Training Loss: 0.0387, Validation Loss: 0.0362\n",
      "Epoch: 526, Training Loss: 0.0387, Validation Loss: 0.0351\n",
      "Epoch: 527, Training Loss: 0.0362, Validation Loss: 0.0362\n",
      "Epoch: 528, Training Loss: 0.0221, Validation Loss: 0.0355\n",
      "Epoch: 529, Training Loss: 0.0383, Validation Loss: 0.0342\n",
      "Validation loss decreased (0.034435 --> 0.034250).  Saving model ...\n",
      "Epoch: 530, Training Loss: 0.0329, Validation Loss: 0.0374\n",
      "Epoch: 531, Training Loss: 0.0325, Validation Loss: 0.0348\n",
      "Epoch: 532, Training Loss: 0.0357, Validation Loss: 0.0359\n",
      "Epoch: 533, Training Loss: 0.0328, Validation Loss: 0.0363\n",
      "Epoch: 534, Training Loss: 0.0262, Validation Loss: 0.0360\n",
      "Epoch: 535, Training Loss: 0.0354, Validation Loss: 0.0362\n",
      "Epoch: 536, Training Loss: 0.0312, Validation Loss: 0.0346\n",
      "Epoch: 537, Training Loss: 0.0369, Validation Loss: 0.0355\n",
      "Epoch: 538, Training Loss: 0.0358, Validation Loss: 0.0351\n",
      "Epoch: 539, Training Loss: 0.0219, Validation Loss: 0.0356\n",
      "Epoch: 540, Training Loss: 0.0290, Validation Loss: 0.0356\n",
      "Epoch: 541, Training Loss: 0.0326, Validation Loss: 0.0363\n",
      "Epoch: 542, Training Loss: 0.0297, Validation Loss: 0.0359\n",
      "Epoch: 543, Training Loss: 0.0441, Validation Loss: 0.0350\n",
      "Epoch: 544, Training Loss: 0.0356, Validation Loss: 0.0348\n",
      "Epoch: 545, Training Loss: 0.0350, Validation Loss: 0.0358\n",
      "Epoch: 546, Training Loss: 0.0278, Validation Loss: 0.0349\n",
      "Epoch: 547, Training Loss: 0.0382, Validation Loss: 0.0367\n",
      "Epoch: 548, Training Loss: 0.0258, Validation Loss: 0.0361\n",
      "Epoch: 549, Training Loss: 0.0317, Validation Loss: 0.0358\n",
      "Epoch: 550, Training Loss: 0.0309, Validation Loss: 0.0347\n",
      "Epoch: 551, Training Loss: 0.0323, Validation Loss: 0.0344\n",
      "Epoch: 552, Training Loss: 0.0375, Validation Loss: 0.0343\n",
      "Epoch: 553, Training Loss: 0.0284, Validation Loss: 0.0355\n",
      "Epoch: 554, Training Loss: 0.0391, Validation Loss: 0.0345\n",
      "Epoch: 555, Training Loss: 0.0329, Validation Loss: 0.0347\n",
      "Epoch: 556, Training Loss: 0.0325, Validation Loss: 0.0354\n",
      "Epoch: 557, Training Loss: 0.0333, Validation Loss: 0.0345\n",
      "Epoch: 558, Training Loss: 0.0287, Validation Loss: 0.0354\n",
      "Epoch: 559, Training Loss: 0.0375, Validation Loss: 0.0343\n",
      "Epoch: 560, Training Loss: 0.0285, Validation Loss: 0.0347\n",
      "Epoch: 561, Training Loss: 0.0269, Validation Loss: 0.0350\n",
      "Epoch: 562, Training Loss: 0.0436, Validation Loss: 0.0344\n",
      "Epoch: 563, Training Loss: 0.0245, Validation Loss: 0.0344\n",
      "Epoch: 564, Training Loss: 0.0278, Validation Loss: 0.0350\n",
      "Epoch: 565, Training Loss: 0.0299, Validation Loss: 0.0357\n",
      "Epoch: 566, Training Loss: 0.0331, Validation Loss: 0.0350\n",
      "Epoch: 567, Training Loss: 0.0376, Validation Loss: 0.0344\n",
      "Epoch: 568, Training Loss: 0.0244, Validation Loss: 0.0337\n",
      "Validation loss decreased (0.034250 --> 0.033723).  Saving model ...\n",
      "Epoch: 569, Training Loss: 0.0391, Validation Loss: 0.0351\n",
      "Epoch: 570, Training Loss: 0.0235, Validation Loss: 0.0346\n",
      "Epoch: 571, Training Loss: 0.0330, Validation Loss: 0.0349\n",
      "Epoch: 572, Training Loss: 0.0303, Validation Loss: 0.0352\n",
      "Epoch: 573, Training Loss: 0.0381, Validation Loss: 0.0355\n",
      "Epoch: 574, Training Loss: 0.0352, Validation Loss: 0.0345\n",
      "Epoch: 575, Training Loss: 0.0288, Validation Loss: 0.0346\n",
      "Epoch: 576, Training Loss: 0.0334, Validation Loss: 0.0356\n",
      "Epoch: 577, Training Loss: 0.0263, Validation Loss: 0.0345\n",
      "Epoch: 578, Training Loss: 0.0292, Validation Loss: 0.0345\n",
      "Epoch: 579, Training Loss: 0.0299, Validation Loss: 0.0363\n",
      "Epoch: 580, Training Loss: 0.0286, Validation Loss: 0.0344\n",
      "Epoch: 581, Training Loss: 0.0334, Validation Loss: 0.0353\n",
      "Epoch: 582, Training Loss: 0.0258, Validation Loss: 0.0348\n",
      "Epoch: 583, Training Loss: 0.0386, Validation Loss: 0.0346\n",
      "Epoch: 584, Training Loss: 0.0393, Validation Loss: 0.0355\n",
      "Epoch: 585, Training Loss: 0.0284, Validation Loss: 0.0352\n",
      "Epoch: 586, Training Loss: 0.0303, Validation Loss: 0.0341\n",
      "Epoch: 587, Training Loss: 0.0373, Validation Loss: 0.0341\n",
      "Epoch: 588, Training Loss: 0.0314, Validation Loss: 0.0346\n",
      "Epoch: 589, Training Loss: 0.0431, Validation Loss: 0.0354\n",
      "Epoch: 590, Training Loss: 0.0352, Validation Loss: 0.0341\n",
      "Epoch: 591, Training Loss: 0.0224, Validation Loss: 0.0342\n",
      "Epoch: 592, Training Loss: 0.0281, Validation Loss: 0.0340\n",
      "Epoch: 593, Training Loss: 0.0354, Validation Loss: 0.0364\n",
      "Epoch: 594, Training Loss: 0.0277, Validation Loss: 0.0349\n",
      "Epoch: 595, Training Loss: 0.0347, Validation Loss: 0.0355\n",
      "Epoch: 596, Training Loss: 0.0297, Validation Loss: 0.0358\n",
      "Epoch: 597, Training Loss: 0.0309, Validation Loss: 0.0338\n",
      "Epoch: 598, Training Loss: 0.0279, Validation Loss: 0.0339\n",
      "Epoch: 599, Training Loss: 0.0342, Validation Loss: 0.0340\n",
      "Epoch: 600, Training Loss: 0.0316, Validation Loss: 0.0361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Progress')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan_model = MultiModalGNNModel(\n",
    "    input_dims=network_dimesions)\n",
    "\n",
    "gan_model = gan_model.to(device)\n",
    "\n",
    "# criterion for regression task\n",
    "criterion = nn.L1Loss() \n",
    "\n",
    "# Fix 7: Better optimizer settings for this problem\n",
    "optimizer = optim.Adam(gan_model.parameters(), lr=0.00001, weight_decay=0.0001)  # Lower LR and weight decay\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopper = EarlyStopping(patience=50, min_delta=0.0001, path='model_checkpoints/gan_checkpoint.pt')\n",
    "\n",
    "# Train the model\n",
    "epochs = 600\n",
    "train_losses_gan, val_losses_gan = train_gnn(epochs, gan_model, optimizer, criterion, train_loader, val_loader, early_stopper)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_gan, label='Training Loss')\n",
    "plt.plot(val_losses_gan, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7f718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(model, test_loader, device, printing=True):\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data_dict in test_loader:\n",
    "            # Move data to device if not already\n",
    "            data_dict = {k: (v.to(device) if hasattr(v, 'to') else v) for k, v in data_dict.items()}\n",
    "            output = model(data_dict)\n",
    "            mask = torch.tensor(data_dict['GINI'].exists, dtype=torch.bool, device=output.device).flatten()\n",
    "            true = data_dict['GINI'].y[mask].cpu().numpy()\n",
    "            pred = output[mask].cpu().numpy()\n",
    "            all_true.append(true)\n",
    "            all_pred.append(pred)\n",
    "    # Concatenate results from all batches\n",
    "    all_true = np.concatenate(all_true, axis=0)\n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "    \n",
    "    # Calculate mean percentage error (MPE)\n",
    "    mpe = np.mean((all_true - all_pred) / all_true) * 100\n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(all_true, all_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(all_true, all_pred))\n",
    "    r2 = r2_score(all_true, all_pred)\n",
    "\n",
    "    if printing:\n",
    "        print(f\"Mean Percentage Error (MPE): {mpe:.2f}%\")\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "        print(f\"R^2 Score: {r2:.4f}\")\n",
    "\n",
    "        # Visualization: Predicted vs True\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(all_true, all_pred, alpha=0.5)\n",
    "        plt.plot([all_true.min(), all_true.max()], [all_true.min(), all_true.max()], 'r--')\n",
    "        plt.xlabel('True GINI')\n",
    "        plt.ylabel('Predicted GINI')\n",
    "        plt.title('Predicted vs True GINI (Test Set)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Visualization: Residuals\n",
    "        residuals = all_true - all_pred\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(residuals, bins=30, alpha=0.7)\n",
    "        plt.xlabel('Residual (True - Predicted)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Residuals Distribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return all_true, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6746e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Percentage Error (MPE): -0.07%\n",
      "Mean Absolute Error (MAE): 0.0321\n",
      "Root Mean Squared Error (RMSE): 0.0435\n",
      "R^2 Score: 0.7328\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true, pred = evaluate_model(gan_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd9baa",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9db84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 05:29:53,596] A new study created in RDB with name: Multimodal_base\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:31:51,539] Trial 0 finished with value: 10.019634246826172 and parameters: {'hidden_size': 84, 'weight_decay': 0.00011497228852444661, 'lr': 0.0003982638859802879, 'n_gat_layers': 3, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'shallow'}. Best is trial 0 with value: 10.019634246826172.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:33:44,595] Trial 1 finished with value: 42.37234115600586 and parameters: {'hidden_size': 36, 'weight_decay': 0.0005289074808098286, 'lr': 0.000285239555112951, 'n_gat_layers': 3, 'n_dim_mlp_layers': 3, 'combination_method': 'concat', 'batch_size': 8, 'mlp_variant': 'shallow'}. Best is trial 0 with value: 10.019634246826172.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:34:21,957] Trial 2 finished with value: 23.88182830810547 and parameters: {'hidden_size': 164, 'weight_decay': 8.66913400136068e-06, 'lr': 6.082866034886886e-05, 'n_gat_layers': 2, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'shallow'}. Best is trial 0 with value: 10.019634246826172.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:34:58,656] Trial 3 finished with value: 15.91946029663086 and parameters: {'hidden_size': 148, 'weight_decay': 0.00014507030027339596, 'lr': 0.00014569502173657746, 'n_gat_layers': 3, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 6, 'mlp_variant': 'deep'}. Best is trial 0 with value: 10.019634246826172.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:35:25,878] Trial 4 finished with value: 16.76740264892578 and parameters: {'hidden_size': 244, 'weight_decay': 0.0007566964560356346, 'lr': 1.541289058112021e-05, 'n_gat_layers': 2, 'n_dim_mlp_layers': 0, 'combination_method': 'concat', 'batch_size': 6, 'mlp_variant': 'deep'}. Best is trial 0 with value: 10.019634246826172.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:38:08,841] Trial 5 finished with value: 8.48172664642334 and parameters: {'hidden_size': 228, 'weight_decay': 7.6217393894459636e-06, 'lr': 0.00018779728198128307, 'n_gat_layers': 2, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'shallow'}. Best is trial 5 with value: 8.48172664642334.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:38:22,549] Trial 6 finished with value: 16.573650360107422 and parameters: {'hidden_size': 196, 'weight_decay': 3.353654359576004e-07, 'lr': 5.0130337012501554e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'concat', 'batch_size': 2, 'mlp_variant': 'shallow'}. Best is trial 5 with value: 8.48172664642334.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:43:13,636] Trial 7 finished with value: 16.774890899658203 and parameters: {'hidden_size': 292, 'weight_decay': 7.451346970770777e-07, 'lr': 6.825598544172754e-05, 'n_gat_layers': 3, 'n_dim_mlp_layers': 1, 'combination_method': 'concat', 'batch_size': 7, 'mlp_variant': 'shallow'}. Best is trial 5 with value: 8.48172664642334.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:45:34,058] Trial 8 finished with value: 10.607619285583496 and parameters: {'hidden_size': 196, 'weight_decay': 9.779072090175622e-07, 'lr': 0.0004094826862404566, 'n_gat_layers': 3, 'n_dim_mlp_layers': 1, 'combination_method': 'concat', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 5 with value: 8.48172664642334.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:46:08,381] Trial 9 finished with value: 16.813798904418945 and parameters: {'hidden_size': 276, 'weight_decay': 7.894906089527745e-07, 'lr': 5.6331273703510736e-05, 'n_gat_layers': 2, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 6, 'mlp_variant': 'deep'}. Best is trial 5 with value: 8.48172664642334.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:46:36,066] Trial 10 finished with value: 16.199237823486328 and parameters: {'hidden_size': 116, 'weight_decay': 8.982911104284349e-06, 'lr': 1.2804578740281013e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 5 with value: 8.48172664642334.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:47:39,675] Trial 11 finished with value: 6.975406646728516 and parameters: {'hidden_size': 68, 'weight_decay': 5.431608003287265e-05, 'lr': 0.0005940867922882339, 'n_gat_layers': 2, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'shallow'}. Best is trial 11 with value: 6.975406646728516.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:48:29,445] Trial 12 finished with value: 7.658288478851318 and parameters: {'hidden_size': 20, 'weight_decay': 3.7192470592667216e-05, 'lr': 0.0008609897662117575, 'n_gat_layers': 2, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 11 with value: 6.975406646728516.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:48:48,857] Trial 13 finished with value: 10.133469581604004 and parameters: {'hidden_size': 20, 'weight_decay': 6.462262252491189e-05, 'lr': 0.00097362065017628, 'n_gat_layers': 2, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 11 with value: 6.975406646728516.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:49:24,749] Trial 14 finished with value: 6.260447025299072 and parameters: {'hidden_size': 68, 'weight_decay': 3.069716614277755e-05, 'lr': 0.000998767505861008, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:49:50,165] Trial 15 finished with value: 7.324895858764648 and parameters: {'hidden_size': 68, 'weight_decay': 2.362579694498049e-05, 'lr': 0.0005875243890725241, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:50:24,556] Trial 16 finished with value: 6.548462867736816 and parameters: {'hidden_size': 84, 'weight_decay': 2.8609706497539164e-06, 'lr': 0.0005287936470909156, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 5, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:50:30,872] Trial 17 finished with value: 17.44435691833496 and parameters: {'hidden_size': 100, 'weight_decay': 2.3565897871977906e-06, 'lr': 0.00023767768913714331, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 5, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:50:38,839] Trial 18 finished with value: 17.367557525634766 and parameters: {'hidden_size': 132, 'weight_decay': 3.6012188676656966e-06, 'lr': 0.00011881346187529669, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 5, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:50:43,193] Trial 19 finished with value: 17.098421096801758 and parameters: {'hidden_size': 52, 'weight_decay': 2.321138959278447e-07, 'lr': 2.879455845186785e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 8, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:51:24,026] Trial 20 finished with value: 6.505186080932617 and parameters: {'hidden_size': 100, 'weight_decay': 1.112297228287878e-07, 'lr': 0.000607087513901205, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:52:07,708] Trial 21 finished with value: 6.725265026092529 and parameters: {'hidden_size': 100, 'weight_decay': 1.421504685615443e-07, 'lr': 0.0006002458909826112, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:52:36,865] Trial 22 finished with value: 7.8597822189331055 and parameters: {'hidden_size': 84, 'weight_decay': 2.7666718693730478e-06, 'lr': 0.00034892846948006835, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 5, 'mlp_variant': 'default'}. Best is trial 14 with value: 6.260447025299072.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:53:42,099] Trial 23 finished with value: 5.521055221557617 and parameters: {'hidden_size': 132, 'weight_decay': 1.1259411015071187e-07, 'lr': 0.0007190064664854979, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:54:50,939] Trial 24 finished with value: 5.735166072845459 and parameters: {'hidden_size': 164, 'weight_decay': 4.09939888463394e-07, 'lr': 0.0009967847460845467, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:55:47,717] Trial 25 finished with value: 5.686326026916504 and parameters: {'hidden_size': 180, 'weight_decay': 3.7704695747285517e-07, 'lr': 0.0007472053844369692, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:57:13,590] Trial 26 finished with value: 6.049141883850098 and parameters: {'hidden_size': 180, 'weight_decay': 4.054001113419475e-07, 'lr': 0.00020892879165311157, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'concat', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:57:38,661] Trial 27 finished with value: 6.886913776397705 and parameters: {'hidden_size': 148, 'weight_decay': 2.1352870374912982e-07, 'lr': 0.0007235948870163946, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 05:59:05,357] Trial 28 finished with value: 5.973209381103516 and parameters: {'hidden_size': 228, 'weight_decay': 1.359085396733731e-06, 'lr': 0.0004354491684703854, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:02:06,168] Trial 29 finished with value: 6.049642562866211 and parameters: {'hidden_size': 180, 'weight_decay': 4.1423006554534797e-07, 'lr': 0.00033332250705286377, 'n_gat_layers': 2, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'default'}. Best is trial 23 with value: 5.521055221557617.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:03:31,823] Trial 30 finished with value: 5.110154151916504 and parameters: {'hidden_size': 132, 'weight_decay': 1.0048360418552718e-07, 'lr': 0.0007729738036493125, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:04:09,711] Trial 31 finished with value: 6.196407794952393 and parameters: {'hidden_size': 132, 'weight_decay': 1.0378634332207128e-07, 'lr': 0.0007758212286505936, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:05:08,086] Trial 32 finished with value: 6.518519878387451 and parameters: {'hidden_size': 164, 'weight_decay': 1.7931555130596741e-07, 'lr': 0.00041137972648274616, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:05:23,757] Trial 33 finished with value: 9.204278945922852 and parameters: {'hidden_size': 132, 'weight_decay': 5.605390424051409e-07, 'lr': 0.0007487629084635256, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:05:52,110] Trial 34 finished with value: 8.704975128173828 and parameters: {'hidden_size': 196, 'weight_decay': 2.846717940104375e-07, 'lr': 0.00027043766278327276, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:07:12,894] Trial 35 finished with value: 5.863323211669922 and parameters: {'hidden_size': 164, 'weight_decay': 0.00030898549747385075, 'lr': 0.00046782961002803466, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'concat', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:08:07,170] Trial 36 finished with value: 7.880014896392822 and parameters: {'hidden_size': 148, 'weight_decay': 1.6547785657687202e-06, 'lr': 0.0009843933757021778, 'n_gat_layers': 2, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:08:20,279] Trial 37 finished with value: 16.49418830871582 and parameters: {'hidden_size': 212, 'weight_decay': 2.0342918070130964e-07, 'lr': 0.00014073614786228476, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:09:03,580] Trial 38 finished with value: 11.273269653320312 and parameters: {'hidden_size': 116, 'weight_decay': 4.780844927818974e-07, 'lr': 0.00030938112736927215, 'n_gat_layers': 1, 'n_dim_mlp_layers': 1, 'combination_method': 'concat', 'batch_size': 7, 'mlp_variant': 'shallow'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:09:42,749] Trial 39 finished with value: 16.43478012084961 and parameters: {'hidden_size': 180, 'weight_decay': 1.367322451727728e-07, 'lr': 8.77996924851043e-05, 'n_gat_layers': 3, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:14:18,843] Trial 40 finished with value: 21.72551727294922 and parameters: {'hidden_size': 244, 'weight_decay': 1.03026223174729e-06, 'lr': 3.266575623312076e-05, 'n_gat_layers': 2, 'n_dim_mlp_layers': 2, 'combination_method': 'concat', 'batch_size': 3, 'mlp_variant': 'shallow'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:15:16,449] Trial 41 finished with value: 6.640458106994629 and parameters: {'hidden_size': 164, 'weight_decay': 0.00021950014747495545, 'lr': 0.0005043944984124961, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'concat', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:16:04,204] Trial 42 finished with value: 7.170539855957031 and parameters: {'hidden_size': 164, 'weight_decay': 4.499268730704841e-06, 'lr': 0.0007373834371382291, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'concat', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:16:48,649] Trial 43 finished with value: 6.51302433013916 and parameters: {'hidden_size': 148, 'weight_decay': 0.0009967873957703976, 'lr': 0.00046906956784023725, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'concat', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:17:32,750] Trial 44 finished with value: 5.844391822814941 and parameters: {'hidden_size': 116, 'weight_decay': 0.00037416269659609183, 'lr': 0.0006948246988476085, 'n_gat_layers': 1, 'n_dim_mlp_layers': 1, 'combination_method': 'concat', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:17:51,970] Trial 45 finished with value: 6.932647705078125 and parameters: {'hidden_size': 116, 'weight_decay': 3.0587380434537695e-07, 'lr': 0.0006781424487112196, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'concat', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:19:21,525] Trial 46 finished with value: 6.318092346191406 and parameters: {'hidden_size': 132, 'weight_decay': 1.6092848999641936e-05, 'lr': 0.00086151477920689, 'n_gat_layers': 2, 'n_dim_mlp_layers': 1, 'combination_method': 'concat', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:19:56,978] Trial 47 finished with value: 9.305877685546875 and parameters: {'hidden_size': 116, 'weight_decay': 0.0001518891880071327, 'lr': 0.00038560414572460226, 'n_gat_layers': 1, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'shallow'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:20:41,304] Trial 48 finished with value: 5.7177605628967285 and parameters: {'hidden_size': 196, 'weight_decay': 0.0005910202996080562, 'lr': 0.0008361988173689257, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:21:21,815] Trial 49 finished with value: 7.109823703765869 and parameters: {'hidden_size': 212, 'weight_decay': 6.554191893547269e-07, 'lr': 0.0008676373841521185, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:23:08,668] Trial 50 finished with value: 6.653984069824219 and parameters: {'hidden_size': 196, 'weight_decay': 7.865234083851939e-05, 'lr': 0.0005817177251713998, 'n_gat_layers': 2, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:24:04,232] Trial 51 finished with value: 5.549409866333008 and parameters: {'hidden_size': 180, 'weight_decay': 0.0004157093006615671, 'lr': 0.0006617595964293359, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:24:44,028] Trial 52 finished with value: 6.787781238555908 and parameters: {'hidden_size': 180, 'weight_decay': 0.00011014796329248994, 'lr': 0.0009767138213435287, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:25:20,189] Trial 53 finished with value: 7.201110363006592 and parameters: {'hidden_size': 212, 'weight_decay': 1.6124996819432046e-07, 'lr': 0.0008111122188309098, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:26:37,836] Trial 54 finished with value: 5.800236701965332 and parameters: {'hidden_size': 228, 'weight_decay': 0.0004980036230115851, 'lr': 0.0005140577671915023, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:27:21,887] Trial 55 finished with value: 6.187071800231934 and parameters: {'hidden_size': 260, 'weight_decay': 5.9997367916582866e-06, 'lr': 0.0006228077356511934, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:28:15,457] Trial 56 finished with value: 6.642007827758789 and parameters: {'hidden_size': 196, 'weight_decay': 1.0405003356495864e-07, 'lr': 0.000886648548912635, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 6, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:29:18,646] Trial 57 finished with value: 7.074859142303467 and parameters: {'hidden_size': 180, 'weight_decay': 0.000880346361211164, 'lr': 0.0006480116472965573, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'shallow'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:30:14,961] Trial 58 finished with value: 6.236143589019775 and parameters: {'hidden_size': 148, 'weight_decay': 0.0006100420352020313, 'lr': 0.000272406709915972, 'n_gat_layers': 1, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:30:42,474] Trial 59 finished with value: 6.397391319274902 and parameters: {'hidden_size': 164, 'weight_decay': 1.6714743435142067e-05, 'lr': 0.0005478575986238202, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 5, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:32:32,906] Trial 60 finished with value: 13.676407814025879 and parameters: {'hidden_size': 132, 'weight_decay': 2.522060784967056e-07, 'lr': 1.9862921727688824e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 7, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:33:36,579] Trial 61 finished with value: 6.4875898361206055 and parameters: {'hidden_size': 212, 'weight_decay': 0.0004510013750324691, 'lr': 0.0005055744128880266, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:34:26,166] Trial 62 finished with value: 6.469284534454346 and parameters: {'hidden_size': 244, 'weight_decay': 0.00023681323913596605, 'lr': 0.000366483152393179, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:35:25,360] Trial 63 finished with value: 5.413401126861572 and parameters: {'hidden_size': 196, 'weight_decay': 0.0005673019599658337, 'lr': 0.0008187829324764109, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:36:11,848] Trial 64 finished with value: 5.745898246765137 and parameters: {'hidden_size': 196, 'weight_decay': 3.961519134917763e-07, 'lr': 0.0008036835046555564, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:36:54,100] Trial 65 finished with value: 5.933966636657715 and parameters: {'hidden_size': 180, 'weight_decay': 0.0006716744778881988, 'lr': 0.0009834758020598763, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:38:19,175] Trial 66 finished with value: 6.338890075683594 and parameters: {'hidden_size': 228, 'weight_decay': 0.0003111257015836375, 'lr': 0.0006770480053922479, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:38:44,224] Trial 67 finished with value: 6.802763938903809 and parameters: {'hidden_size': 148, 'weight_decay': 1.5072163545829543e-07, 'lr': 0.0008409091709852721, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:39:28,488] Trial 68 finished with value: 21.912837982177734 and parameters: {'hidden_size': 180, 'weight_decay': 8.957572842465214e-07, 'lr': 1.0466877080990538e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:41:24,152] Trial 69 finished with value: 11.515249252319336 and parameters: {'hidden_size': 196, 'weight_decay': 0.000188731340136425, 'lr': 0.00044191444342360156, 'n_gat_layers': 3, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'default'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:42:51,963] Trial 70 finished with value: 8.404669761657715 and parameters: {'hidden_size': 164, 'weight_decay': 0.0007393008913710757, 'lr': 0.0005694707534740324, 'n_gat_layers': 2, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:43:12,925] Trial 71 finished with value: 9.134297370910645 and parameters: {'hidden_size': 196, 'weight_decay': 3.8396871135087096e-07, 'lr': 0.0007279405295950751, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:43:43,769] Trial 72 finished with value: 7.426531791687012 and parameters: {'hidden_size': 212, 'weight_decay': 5.534297747750687e-07, 'lr': 0.0007880204109117321, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:44:16,420] Trial 73 finished with value: 7.016190052032471 and parameters: {'hidden_size': 180, 'weight_decay': 2.0043448909552825e-06, 'lr': 0.0008578620760225818, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 30 with value: 5.110154151916504.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:45:23,861] Trial 74 finished with value: 4.794276237487793 and parameters: {'hidden_size': 148, 'weight_decay': 3.414375524585915e-07, 'lr': 0.0006502342591153078, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:45:56,037] Trial 75 finished with value: 5.947178363800049 and parameters: {'hidden_size': 132, 'weight_decay': 2.3812967045137096e-07, 'lr': 0.0006310690652327634, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:46:05,987] Trial 76 finished with value: 16.709753036499023 and parameters: {'hidden_size': 148, 'weight_decay': 1.1122593996914859e-06, 'lr': 7.826518743071483e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:46:51,082] Trial 77 finished with value: 5.931066989898682 and parameters: {'hidden_size': 100, 'weight_decay': 1.3931214620357907e-07, 'lr': 0.0006919510758528655, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'shallow'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:47:33,513] Trial 78 finished with value: 6.129209995269775 and parameters: {'hidden_size': 164, 'weight_decay': 1.9466296468942688e-07, 'lr': 0.0009206941074639102, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:48:33,194] Trial 79 finished with value: 6.894773483276367 and parameters: {'hidden_size': 132, 'weight_decay': 3.083772006697778e-07, 'lr': 0.00019744986649697114, 'n_gat_layers': 1, 'n_dim_mlp_layers': 1, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'default'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:49:30,828] Trial 80 finished with value: 6.775575637817383 and parameters: {'hidden_size': 164, 'weight_decay': 0.0003923621513126398, 'lr': 0.00040733580569630654, 'n_gat_layers': 1, 'n_dim_mlp_layers': 3, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:50:01,020] Trial 81 finished with value: 6.409878253936768 and parameters: {'hidden_size': 196, 'weight_decay': 6.328144959039204e-07, 'lr': 0.00078303087890977, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 2, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:51:15,331] Trial 82 finished with value: 5.532454967498779 and parameters: {'hidden_size': 180, 'weight_decay': 4.435491191427889e-07, 'lr': 0.0005584207932490243, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:51:32,675] Trial 83 finished with value: 15.475231170654297 and parameters: {'hidden_size': 148, 'weight_decay': 8.056703131986717e-07, 'lr': 4.461353115689401e-05, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:52:28,810] Trial 84 finished with value: 5.32084846496582 and parameters: {'hidden_size': 180, 'weight_decay': 1.2136218853444438e-07, 'lr': 0.0005540167763718412, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:54:20,655] Trial 85 finished with value: 5.998543739318848 and parameters: {'hidden_size': 180, 'weight_decay': 1.2647702089690389e-07, 'lr': 0.00016635601307387596, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:55:09,815] Trial 86 finished with value: 7.465686798095703 and parameters: {'hidden_size': 180, 'weight_decay': 1.0674016363132002e-07, 'lr': 0.00046047825945470366, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:55:52,541] Trial 87 finished with value: 5.847451686859131 and parameters: {'hidden_size': 212, 'weight_decay': 1.7383049349797343e-07, 'lr': 0.0005496935036419824, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:57:09,100] Trial 88 finished with value: 10.5740327835083 and parameters: {'hidden_size': 180, 'weight_decay': 2.735993737570729e-07, 'lr': 0.0006090325543684589, 'n_gat_layers': 3, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:57:44,276] Trial 89 finished with value: 6.152742862701416 and parameters: {'hidden_size': 196, 'weight_decay': 2.0299248610233623e-07, 'lr': 0.0004926695508781426, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:58:36,244] Trial 90 finished with value: 7.5346174240112305 and parameters: {'hidden_size': 148, 'weight_decay': 1.1900652296566464e-07, 'lr': 0.0003192749757353629, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 06:59:17,631] Trial 91 finished with value: 6.277205944061279 and parameters: {'hidden_size': 164, 'weight_decay': 5.243754593998554e-07, 'lr': 0.0007031906429507556, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:00:08,287] Trial 92 finished with value: 6.040626049041748 and parameters: {'hidden_size': 164, 'weight_decay': 3.938515263297512e-05, 'lr': 0.0009958627715116722, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:00:45,097] Trial 93 finished with value: 5.831883907318115 and parameters: {'hidden_size': 132, 'weight_decay': 3.617604235373341e-07, 'lr': 0.0007496028931585615, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:01:27,331] Trial 94 finished with value: 6.553142547607422 and parameters: {'hidden_size': 196, 'weight_decay': 4.534032230791168e-07, 'lr': 0.0006304745902987385, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:02:48,431] Trial 95 finished with value: 5.929046154022217 and parameters: {'hidden_size': 292, 'weight_decay': 0.0005266085197171891, 'lr': 0.000911479425995336, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'shallow'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:03:16,820] Trial 96 finished with value: 6.024346351623535 and parameters: {'hidden_size': 116, 'weight_decay': 1.4709660236524915e-07, 'lr': 0.0005453090890962921, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 8, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:04:09,162] Trial 97 finished with value: 5.936729431152344 and parameters: {'hidden_size': 164, 'weight_decay': 1.1279695048602187e-05, 'lr': 0.0007703209434454244, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'default'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:04:47,099] Trial 98 finished with value: 6.475272178649902 and parameters: {'hidden_size': 180, 'weight_decay': 2.3597456875320463e-07, 'lr': 0.0006666603022916722, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 4, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n",
      "/home/jovyan/environments/dlss_env/lib/python3.11/site-packages/optuna/distributions.py:702: UserWarning: The distribution is specified by [20, 300] and step=16, but the range is not divisible by `step`. It will be replaced by [20, 292].\n",
      "  warnings.warn(\n",
      "[I 2025-08-14 07:05:31,023] Trial 99 finished with value: 5.934716701507568 and parameters: {'hidden_size': 148, 'weight_decay': 3.049366937417984e-07, 'lr': 0.0008750639800500466, 'n_gat_layers': 1, 'n_dim_mlp_layers': 2, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}. Best is trial 74 with value: 4.794276237487793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'hidden_size': 148, 'weight_decay': 3.414375524585915e-07, 'lr': 0.0006502342591153078, 'n_gat_layers': 1, 'n_dim_mlp_layers': 0, 'combination_method': 'attention', 'batch_size': 3, 'mlp_variant': 'deep'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def move_data_dict_to_device(data_dict, device):\n",
    "    moved = {}\n",
    "    for k, v in data_dict.items():\n",
    "        if hasattr(v, 'to'):\n",
    "            moved[k] = v.to(device)\n",
    "        else:\n",
    "            moved[k] = v\n",
    "    return moved\n",
    "\n",
    "train_set = [move_data_dict_to_device(d, device) for d in train_set]\n",
    "val_set = [move_data_dict_to_device(d, device) for d in val_set]\n",
    "test_set = [move_data_dict_to_device(d, device) for d in test_set]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 20, 300, step=16)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-7, 1e-3, log=True)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    n_gat_layers = trial.suggest_int(\"n_gat_layers\", 1, 3)\n",
    "    n_dim_mlp_layers = trial.suggest_int(\"n_dim_mlp_layers\", 0, 3)\n",
    "    combination_method = trial.suggest_categorical(\"combination_method\", ['concat', 'attention'])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 2, 8, step=1)\n",
    "    \n",
    "    mlp_variant = trial.suggest_categorical(\"mlp_variant\", ['default', 'deep', 'shallow'])\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    # test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    gan_model = MultiModalGNNModel(\n",
    "        input_dims=network_dimesions, hidden_size=hidden_size,\n",
    "        n_gat_layers=n_gat_layers, n_dim_mlp_layers=n_dim_mlp_layers,\n",
    "        combination_method=combination_method,\n",
    "        mlp_variant=mlp_variant)\n",
    "    \n",
    "    gan_model = gan_model.to(device)\n",
    "    \n",
    "    # criterion for regression task\n",
    "    criterion = MeanAbsolutePercentageError().to(device)\n",
    "    \n",
    "    # Fix 7: Better optimizer settings for this problem\n",
    "    optimizer = optim.Adam(gan_model.parameters(), lr=lr, weight_decay=weight_decay)  # Lower LR and weight decay\n",
    "    \n",
    "    # Initialize early stopping\n",
    "    early_stopper = EarlyStopping(patience=30, min_delta=0.00001, path='model_checkpoints/gan_checkpoint_optuna.pt', printing=False)\n",
    "    \n",
    "    # Train the model\n",
    "    epochs = 600\n",
    "    train_losses_gan, val_losses_gan = train_gnn(epochs, gan_model, optimizer, criterion, train_loader, val_loader, early_stopper, printing=False)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    true, pred = evaluate_model(gan_model, val_loader, device, printing =False)\n",
    "    mape = np.mean(np.abs((true - pred) / np.abs(true))) * 100\n",
    "    \n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name = \"Multimodal_base\",\n",
    "    storage=\"sqlite:///optuna_study_optimized.db\",\n",
    "    direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fcb2f",
   "metadata": {},
   "source": [
    "best performance with deep MLP and only 1 GAT layer..... maybe network is not soooo important after all...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
